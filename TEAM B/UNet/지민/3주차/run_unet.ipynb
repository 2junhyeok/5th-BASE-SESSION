{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n        (async () => {\n            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n            url.searchParams.set('tensorboardColab', 'true');\n            const iframe = document.createElement('iframe');\n            iframe.src = url;\n            iframe.setAttribute('width', '100%');\n            iframe.setAttribute('height', '800');\n            iframe.setAttribute('frameborder', 0);\n            document.body.appendChild(iframe);\n        })();\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensorboard --logdir='./log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure(640x480)\n"
     ]
    }
   ],
   "source": [
    "!python '/home/work/jimin/U-Net/data_read.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python '/home/work/jimin/U-Net/dataset.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python '/home/work/jimin/U-Net/util.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-25 05:22:43.889129: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-25 05:22:43.927048: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-25 05:22:43.927084: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-25 05:22:43.928140: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-25 05:22:43.933954: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-25 05:22:44.793161: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "!python '/home/work/jimin/U-Net/model.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-25 05:32:14.994591: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-25 05:32:15.034592: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-25 05:32:15.034633: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-25 05:32:15.035737: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-25 05:32:15.041926: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-25 05:32:15.902086: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "learning rate: 1.0000e-03\n",
      "batch size: 2\n",
      "number of epoch: 100\n",
      "data dir: /home/work/jimin/U-Net/datasets\n",
      "ckpt dir: /home/work/jimin/U-Net/checkpoint\n",
      "log dir: /home/work/jimin/U-Net/log\n",
      "result dir: /home/work/jimin/U-Net/result\n",
      "mode: train\n",
      "TRAIN: EPOCH 0001 / 0100 | BATCH 0001 / 0012 | LOSS 0.7481\n",
      "TRAIN: EPOCH 0001 / 0100 | BATCH 0002 / 0012 | LOSS 0.6773\n",
      "TRAIN: EPOCH 0001 / 0100 | BATCH 0003 / 0012 | LOSS 0.6398\n",
      "TRAIN: EPOCH 0001 / 0100 | BATCH 0004 / 0012 | LOSS 0.6206\n",
      "TRAIN: EPOCH 0001 / 0100 | BATCH 0005 / 0012 | LOSS 0.5986\n",
      "TRAIN: EPOCH 0001 / 0100 | BATCH 0006 / 0012 | LOSS 0.5715\n",
      "TRAIN: EPOCH 0001 / 0100 | BATCH 0007 / 0012 | LOSS 0.5495\n",
      "TRAIN: EPOCH 0001 / 0100 | BATCH 0008 / 0012 | LOSS 0.5343\n",
      "TRAIN: EPOCH 0001 / 0100 | BATCH 0009 / 0012 | LOSS 0.5196\n",
      "TRAIN: EPOCH 0001 / 0100 | BATCH 0010 / 0012 | LOSS 0.5082\n",
      "TRAIN: EPOCH 0001 / 0100 | BATCH 0011 / 0012 | LOSS 0.4980\n",
      "TRAIN: EPOCH 0001 / 0100 | BATCH 0012 / 0012 | LOSS 0.4893\n",
      "VALID: EPOCH 0001 / 0100 | BATCH 0001 / 0002 | LOSS 0.5067\n",
      "VALID: EPOCH 0001 / 0100 | BATCH 0002 / 0002 | LOSS 0.5046\n",
      "TRAIN: EPOCH 0002 / 0100 | BATCH 0001 / 0012 | LOSS 0.3752\n",
      "TRAIN: EPOCH 0002 / 0100 | BATCH 0002 / 0012 | LOSS 0.3732\n",
      "TRAIN: EPOCH 0002 / 0100 | BATCH 0003 / 0012 | LOSS 0.3722\n",
      "TRAIN: EPOCH 0002 / 0100 | BATCH 0004 / 0012 | LOSS 0.3682\n",
      "TRAIN: EPOCH 0002 / 0100 | BATCH 0005 / 0012 | LOSS 0.3656\n",
      "TRAIN: EPOCH 0002 / 0100 | BATCH 0006 / 0012 | LOSS 0.3620\n",
      "TRAIN: EPOCH 0002 / 0100 | BATCH 0007 / 0012 | LOSS 0.3597\n",
      "TRAIN: EPOCH 0002 / 0100 | BATCH 0008 / 0012 | LOSS 0.3619\n",
      "TRAIN: EPOCH 0002 / 0100 | BATCH 0009 / 0012 | LOSS 0.3593\n",
      "TRAIN: EPOCH 0002 / 0100 | BATCH 0010 / 0012 | LOSS 0.3549\n",
      "TRAIN: EPOCH 0002 / 0100 | BATCH 0011 / 0012 | LOSS 0.3526\n",
      "TRAIN: EPOCH 0002 / 0100 | BATCH 0012 / 0012 | LOSS 0.3511\n",
      "VALID: EPOCH 0002 / 0100 | BATCH 0001 / 0002 | LOSS 0.3460\n",
      "VALID: EPOCH 0002 / 0100 | BATCH 0002 / 0002 | LOSS 0.3510\n",
      "TRAIN: EPOCH 0003 / 0100 | BATCH 0001 / 0012 | LOSS 0.3232\n",
      "TRAIN: EPOCH 0003 / 0100 | BATCH 0002 / 0012 | LOSS 0.3214\n",
      "TRAIN: EPOCH 0003 / 0100 | BATCH 0003 / 0012 | LOSS 0.3259\n",
      "TRAIN: EPOCH 0003 / 0100 | BATCH 0004 / 0012 | LOSS 0.3262\n",
      "TRAIN: EPOCH 0003 / 0100 | BATCH 0005 / 0012 | LOSS 0.3236\n",
      "TRAIN: EPOCH 0003 / 0100 | BATCH 0006 / 0012 | LOSS 0.3232\n",
      "TRAIN: EPOCH 0003 / 0100 | BATCH 0007 / 0012 | LOSS 0.3197\n",
      "TRAIN: EPOCH 0003 / 0100 | BATCH 0008 / 0012 | LOSS 0.3247\n",
      "TRAIN: EPOCH 0003 / 0100 | BATCH 0009 / 0012 | LOSS 0.3238\n",
      "TRAIN: EPOCH 0003 / 0100 | BATCH 0010 / 0012 | LOSS 0.3224\n",
      "TRAIN: EPOCH 0003 / 0100 | BATCH 0011 / 0012 | LOSS 0.3226\n",
      "TRAIN: EPOCH 0003 / 0100 | BATCH 0012 / 0012 | LOSS 0.3212\n",
      "VALID: EPOCH 0003 / 0100 | BATCH 0001 / 0002 | LOSS 0.3067\n",
      "VALID: EPOCH 0003 / 0100 | BATCH 0002 / 0002 | LOSS 0.3139\n",
      "TRAIN: EPOCH 0004 / 0100 | BATCH 0001 / 0012 | LOSS 0.2939\n",
      "TRAIN: EPOCH 0004 / 0100 | BATCH 0002 / 0012 | LOSS 0.2932\n",
      "TRAIN: EPOCH 0004 / 0100 | BATCH 0003 / 0012 | LOSS 0.2971\n",
      "TRAIN: EPOCH 0004 / 0100 | BATCH 0004 / 0012 | LOSS 0.2941\n",
      "TRAIN: EPOCH 0004 / 0100 | BATCH 0005 / 0012 | LOSS 0.2925\n",
      "TRAIN: EPOCH 0004 / 0100 | BATCH 0006 / 0012 | LOSS 0.2935\n",
      "TRAIN: EPOCH 0004 / 0100 | BATCH 0007 / 0012 | LOSS 0.2940\n",
      "TRAIN: EPOCH 0004 / 0100 | BATCH 0008 / 0012 | LOSS 0.2920\n",
      "TRAIN: EPOCH 0004 / 0100 | BATCH 0009 / 0012 | LOSS 0.2901\n",
      "TRAIN: EPOCH 0004 / 0100 | BATCH 0010 / 0012 | LOSS 0.2880\n",
      "TRAIN: EPOCH 0004 / 0100 | BATCH 0011 / 0012 | LOSS 0.2858\n",
      "TRAIN: EPOCH 0004 / 0100 | BATCH 0012 / 0012 | LOSS 0.2845\n",
      "VALID: EPOCH 0004 / 0100 | BATCH 0001 / 0002 | LOSS 0.2849\n",
      "VALID: EPOCH 0004 / 0100 | BATCH 0002 / 0002 | LOSS 0.2915\n",
      "TRAIN: EPOCH 0005 / 0100 | BATCH 0001 / 0012 | LOSS 0.2580\n",
      "TRAIN: EPOCH 0005 / 0100 | BATCH 0002 / 0012 | LOSS 0.2636\n",
      "TRAIN: EPOCH 0005 / 0100 | BATCH 0003 / 0012 | LOSS 0.2693\n",
      "TRAIN: EPOCH 0005 / 0100 | BATCH 0004 / 0012 | LOSS 0.2667\n",
      "TRAIN: EPOCH 0005 / 0100 | BATCH 0005 / 0012 | LOSS 0.2670\n",
      "TRAIN: EPOCH 0005 / 0100 | BATCH 0006 / 0012 | LOSS 0.2644\n",
      "TRAIN: EPOCH 0005 / 0100 | BATCH 0007 / 0012 | LOSS 0.2629\n",
      "TRAIN: EPOCH 0005 / 0100 | BATCH 0008 / 0012 | LOSS 0.2628\n",
      "TRAIN: EPOCH 0005 / 0100 | BATCH 0009 / 0012 | LOSS 0.2611\n",
      "TRAIN: EPOCH 0005 / 0100 | BATCH 0010 / 0012 | LOSS 0.2634\n",
      "TRAIN: EPOCH 0005 / 0100 | BATCH 0011 / 0012 | LOSS 0.2614\n",
      "TRAIN: EPOCH 0005 / 0100 | BATCH 0012 / 0012 | LOSS 0.2616\n",
      "VALID: EPOCH 0005 / 0100 | BATCH 0001 / 0002 | LOSS 0.2648\n",
      "VALID: EPOCH 0005 / 0100 | BATCH 0002 / 0002 | LOSS 0.2705\n",
      "TRAIN: EPOCH 0006 / 0100 | BATCH 0001 / 0012 | LOSS 0.2563\n",
      "TRAIN: EPOCH 0006 / 0100 | BATCH 0002 / 0012 | LOSS 0.2589\n",
      "TRAIN: EPOCH 0006 / 0100 | BATCH 0003 / 0012 | LOSS 0.2546\n",
      "TRAIN: EPOCH 0006 / 0100 | BATCH 0004 / 0012 | LOSS 0.2517\n",
      "TRAIN: EPOCH 0006 / 0100 | BATCH 0005 / 0012 | LOSS 0.2521\n",
      "TRAIN: EPOCH 0006 / 0100 | BATCH 0006 / 0012 | LOSS 0.2501\n",
      "TRAIN: EPOCH 0006 / 0100 | BATCH 0007 / 0012 | LOSS 0.2521\n",
      "TRAIN: EPOCH 0006 / 0100 | BATCH 0008 / 0012 | LOSS 0.2502\n",
      "TRAIN: EPOCH 0006 / 0100 | BATCH 0009 / 0012 | LOSS 0.2474\n",
      "TRAIN: EPOCH 0006 / 0100 | BATCH 0010 / 0012 | LOSS 0.2452\n",
      "TRAIN: EPOCH 0006 / 0100 | BATCH 0011 / 0012 | LOSS 0.2446\n",
      "TRAIN: EPOCH 0006 / 0100 | BATCH 0012 / 0012 | LOSS 0.2440\n",
      "VALID: EPOCH 0006 / 0100 | BATCH 0001 / 0002 | LOSS 0.2686\n",
      "VALID: EPOCH 0006 / 0100 | BATCH 0002 / 0002 | LOSS 0.2792\n",
      "TRAIN: EPOCH 0007 / 0100 | BATCH 0001 / 0012 | LOSS 0.2236\n",
      "TRAIN: EPOCH 0007 / 0100 | BATCH 0002 / 0012 | LOSS 0.2253\n",
      "TRAIN: EPOCH 0007 / 0100 | BATCH 0003 / 0012 | LOSS 0.2276\n",
      "TRAIN: EPOCH 0007 / 0100 | BATCH 0004 / 0012 | LOSS 0.2275\n",
      "TRAIN: EPOCH 0007 / 0100 | BATCH 0005 / 0012 | LOSS 0.2278\n",
      "TRAIN: EPOCH 0007 / 0100 | BATCH 0006 / 0012 | LOSS 0.2274\n",
      "TRAIN: EPOCH 0007 / 0100 | BATCH 0007 / 0012 | LOSS 0.2299\n",
      "TRAIN: EPOCH 0007 / 0100 | BATCH 0008 / 0012 | LOSS 0.2293\n",
      "TRAIN: EPOCH 0007 / 0100 | BATCH 0009 / 0012 | LOSS 0.2315\n",
      "TRAIN: EPOCH 0007 / 0100 | BATCH 0010 / 0012 | LOSS 0.2328\n",
      "TRAIN: EPOCH 0007 / 0100 | BATCH 0011 / 0012 | LOSS 0.2342\n",
      "TRAIN: EPOCH 0007 / 0100 | BATCH 0012 / 0012 | LOSS 0.2347\n",
      "VALID: EPOCH 0007 / 0100 | BATCH 0001 / 0002 | LOSS 0.2308\n",
      "VALID: EPOCH 0007 / 0100 | BATCH 0002 / 0002 | LOSS 0.2451\n",
      "TRAIN: EPOCH 0008 / 0100 | BATCH 0001 / 0012 | LOSS 0.2239\n",
      "TRAIN: EPOCH 0008 / 0100 | BATCH 0002 / 0012 | LOSS 0.2197\n",
      "TRAIN: EPOCH 0008 / 0100 | BATCH 0003 / 0012 | LOSS 0.2337\n",
      "TRAIN: EPOCH 0008 / 0100 | BATCH 0004 / 0012 | LOSS 0.2381\n",
      "TRAIN: EPOCH 0008 / 0100 | BATCH 0005 / 0012 | LOSS 0.2363\n",
      "TRAIN: EPOCH 0008 / 0100 | BATCH 0006 / 0012 | LOSS 0.2344\n",
      "TRAIN: EPOCH 0008 / 0100 | BATCH 0007 / 0012 | LOSS 0.2373\n",
      "TRAIN: EPOCH 0008 / 0100 | BATCH 0008 / 0012 | LOSS 0.2378\n",
      "TRAIN: EPOCH 0008 / 0100 | BATCH 0009 / 0012 | LOSS 0.2366\n",
      "TRAIN: EPOCH 0008 / 0100 | BATCH 0010 / 0012 | LOSS 0.2366\n",
      "TRAIN: EPOCH 0008 / 0100 | BATCH 0011 / 0012 | LOSS 0.2347\n",
      "TRAIN: EPOCH 0008 / 0100 | BATCH 0012 / 0012 | LOSS 0.2365\n",
      "VALID: EPOCH 0008 / 0100 | BATCH 0001 / 0002 | LOSS 0.2438\n",
      "VALID: EPOCH 0008 / 0100 | BATCH 0002 / 0002 | LOSS 0.2535\n",
      "TRAIN: EPOCH 0009 / 0100 | BATCH 0001 / 0012 | LOSS 0.2199\n",
      "TRAIN: EPOCH 0009 / 0100 | BATCH 0002 / 0012 | LOSS 0.2089\n",
      "TRAIN: EPOCH 0009 / 0100 | BATCH 0003 / 0012 | LOSS 0.2157\n",
      "TRAIN: EPOCH 0009 / 0100 | BATCH 0004 / 0012 | LOSS 0.2245\n",
      "TRAIN: EPOCH 0009 / 0100 | BATCH 0005 / 0012 | LOSS 0.2233\n",
      "TRAIN: EPOCH 0009 / 0100 | BATCH 0006 / 0012 | LOSS 0.2226\n",
      "TRAIN: EPOCH 0009 / 0100 | BATCH 0007 / 0012 | LOSS 0.2213\n",
      "TRAIN: EPOCH 0009 / 0100 | BATCH 0008 / 0012 | LOSS 0.2211\n",
      "TRAIN: EPOCH 0009 / 0100 | BATCH 0009 / 0012 | LOSS 0.2234\n",
      "TRAIN: EPOCH 0009 / 0100 | BATCH 0010 / 0012 | LOSS 0.2231\n",
      "TRAIN: EPOCH 0009 / 0100 | BATCH 0011 / 0012 | LOSS 0.2230\n",
      "TRAIN: EPOCH 0009 / 0100 | BATCH 0012 / 0012 | LOSS 0.2239\n",
      "VALID: EPOCH 0009 / 0100 | BATCH 0001 / 0002 | LOSS 0.2166\n",
      "VALID: EPOCH 0009 / 0100 | BATCH 0002 / 0002 | LOSS 0.2311\n",
      "TRAIN: EPOCH 0010 / 0100 | BATCH 0001 / 0012 | LOSS 0.2233\n",
      "TRAIN: EPOCH 0010 / 0100 | BATCH 0002 / 0012 | LOSS 0.2172\n",
      "TRAIN: EPOCH 0010 / 0100 | BATCH 0003 / 0012 | LOSS 0.2170\n",
      "TRAIN: EPOCH 0010 / 0100 | BATCH 0004 / 0012 | LOSS 0.2133\n",
      "TRAIN: EPOCH 0010 / 0100 | BATCH 0005 / 0012 | LOSS 0.2144\n",
      "TRAIN: EPOCH 0010 / 0100 | BATCH 0006 / 0012 | LOSS 0.2146\n",
      "TRAIN: EPOCH 0010 / 0100 | BATCH 0007 / 0012 | LOSS 0.2163\n",
      "TRAIN: EPOCH 0010 / 0100 | BATCH 0008 / 0012 | LOSS 0.2157\n",
      "TRAIN: EPOCH 0010 / 0100 | BATCH 0009 / 0012 | LOSS 0.2150\n",
      "TRAIN: EPOCH 0010 / 0100 | BATCH 0010 / 0012 | LOSS 0.2135\n",
      "TRAIN: EPOCH 0010 / 0100 | BATCH 0011 / 0012 | LOSS 0.2153\n",
      "TRAIN: EPOCH 0010 / 0100 | BATCH 0012 / 0012 | LOSS 0.2166\n",
      "VALID: EPOCH 0010 / 0100 | BATCH 0001 / 0002 | LOSS 0.2243\n",
      "VALID: EPOCH 0010 / 0100 | BATCH 0002 / 0002 | LOSS 0.2341\n",
      "TRAIN: EPOCH 0011 / 0100 | BATCH 0001 / 0012 | LOSS 0.2293\n",
      "TRAIN: EPOCH 0011 / 0100 | BATCH 0002 / 0012 | LOSS 0.2200\n",
      "TRAIN: EPOCH 0011 / 0100 | BATCH 0003 / 0012 | LOSS 0.2154\n",
      "TRAIN: EPOCH 0011 / 0100 | BATCH 0004 / 0012 | LOSS 0.2106\n",
      "TRAIN: EPOCH 0011 / 0100 | BATCH 0005 / 0012 | LOSS 0.2143\n",
      "TRAIN: EPOCH 0011 / 0100 | BATCH 0006 / 0012 | LOSS 0.2164\n",
      "TRAIN: EPOCH 0011 / 0100 | BATCH 0007 / 0012 | LOSS 0.2148\n",
      "TRAIN: EPOCH 0011 / 0100 | BATCH 0008 / 0012 | LOSS 0.2150\n",
      "TRAIN: EPOCH 0011 / 0100 | BATCH 0009 / 0012 | LOSS 0.2145\n",
      "TRAIN: EPOCH 0011 / 0100 | BATCH 0010 / 0012 | LOSS 0.2137\n",
      "TRAIN: EPOCH 0011 / 0100 | BATCH 0011 / 0012 | LOSS 0.2134\n",
      "TRAIN: EPOCH 0011 / 0100 | BATCH 0012 / 0012 | LOSS 0.2157\n",
      "VALID: EPOCH 0011 / 0100 | BATCH 0001 / 0002 | LOSS 0.2284\n",
      "VALID: EPOCH 0011 / 0100 | BATCH 0002 / 0002 | LOSS 0.2418\n",
      "TRAIN: EPOCH 0012 / 0100 | BATCH 0001 / 0012 | LOSS 0.2152\n",
      "TRAIN: EPOCH 0012 / 0100 | BATCH 0002 / 0012 | LOSS 0.2170\n",
      "TRAIN: EPOCH 0012 / 0100 | BATCH 0003 / 0012 | LOSS 0.2105\n",
      "TRAIN: EPOCH 0012 / 0100 | BATCH 0004 / 0012 | LOSS 0.2046\n",
      "TRAIN: EPOCH 0012 / 0100 | BATCH 0005 / 0012 | LOSS 0.2022\n",
      "TRAIN: EPOCH 0012 / 0100 | BATCH 0006 / 0012 | LOSS 0.2037\n",
      "TRAIN: EPOCH 0012 / 0100 | BATCH 0007 / 0012 | LOSS 0.2036\n",
      "TRAIN: EPOCH 0012 / 0100 | BATCH 0008 / 0012 | LOSS 0.2023\n",
      "TRAIN: EPOCH 0012 / 0100 | BATCH 0009 / 0012 | LOSS 0.2016\n",
      "TRAIN: EPOCH 0012 / 0100 | BATCH 0010 / 0012 | LOSS 0.2026\n",
      "TRAIN: EPOCH 0012 / 0100 | BATCH 0011 / 0012 | LOSS 0.2065\n",
      "TRAIN: EPOCH 0012 / 0100 | BATCH 0012 / 0012 | LOSS 0.2080\n",
      "VALID: EPOCH 0012 / 0100 | BATCH 0001 / 0002 | LOSS 0.2033\n",
      "VALID: EPOCH 0012 / 0100 | BATCH 0002 / 0002 | LOSS 0.2170\n",
      "TRAIN: EPOCH 0013 / 0100 | BATCH 0001 / 0012 | LOSS 0.2003\n",
      "TRAIN: EPOCH 0013 / 0100 | BATCH 0002 / 0012 | LOSS 0.2040\n",
      "TRAIN: EPOCH 0013 / 0100 | BATCH 0003 / 0012 | LOSS 0.2150\n",
      "TRAIN: EPOCH 0013 / 0100 | BATCH 0004 / 0012 | LOSS 0.2113\n",
      "TRAIN: EPOCH 0013 / 0100 | BATCH 0005 / 0012 | LOSS 0.2146\n",
      "TRAIN: EPOCH 0013 / 0100 | BATCH 0006 / 0012 | LOSS 0.2164\n",
      "TRAIN: EPOCH 0013 / 0100 | BATCH 0007 / 0012 | LOSS 0.2149\n",
      "TRAIN: EPOCH 0013 / 0100 | BATCH 0008 / 0012 | LOSS 0.2137\n",
      "TRAIN: EPOCH 0013 / 0100 | BATCH 0009 / 0012 | LOSS 0.2123\n",
      "TRAIN: EPOCH 0013 / 0100 | BATCH 0010 / 0012 | LOSS 0.2102\n",
      "TRAIN: EPOCH 0013 / 0100 | BATCH 0011 / 0012 | LOSS 0.2092\n",
      "TRAIN: EPOCH 0013 / 0100 | BATCH 0012 / 0012 | LOSS 0.2086\n",
      "VALID: EPOCH 0013 / 0100 | BATCH 0001 / 0002 | LOSS 0.1975\n",
      "VALID: EPOCH 0013 / 0100 | BATCH 0002 / 0002 | LOSS 0.2105\n",
      "TRAIN: EPOCH 0014 / 0100 | BATCH 0001 / 0012 | LOSS 0.2044\n",
      "TRAIN: EPOCH 0014 / 0100 | BATCH 0002 / 0012 | LOSS 0.2000\n",
      "TRAIN: EPOCH 0014 / 0100 | BATCH 0003 / 0012 | LOSS 0.1974\n",
      "TRAIN: EPOCH 0014 / 0100 | BATCH 0004 / 0012 | LOSS 0.1944\n",
      "TRAIN: EPOCH 0014 / 0100 | BATCH 0005 / 0012 | LOSS 0.2023\n",
      "TRAIN: EPOCH 0014 / 0100 | BATCH 0006 / 0012 | LOSS 0.1993\n",
      "TRAIN: EPOCH 0014 / 0100 | BATCH 0007 / 0012 | LOSS 0.2004\n",
      "TRAIN: EPOCH 0014 / 0100 | BATCH 0008 / 0012 | LOSS 0.2017\n",
      "TRAIN: EPOCH 0014 / 0100 | BATCH 0009 / 0012 | LOSS 0.2030\n",
      "TRAIN: EPOCH 0014 / 0100 | BATCH 0010 / 0012 | LOSS 0.2031\n",
      "TRAIN: EPOCH 0014 / 0100 | BATCH 0011 / 0012 | LOSS 0.2018\n",
      "TRAIN: EPOCH 0014 / 0100 | BATCH 0012 / 0012 | LOSS 0.2016\n",
      "VALID: EPOCH 0014 / 0100 | BATCH 0001 / 0002 | LOSS 0.1928\n",
      "VALID: EPOCH 0014 / 0100 | BATCH 0002 / 0002 | LOSS 0.2133\n",
      "TRAIN: EPOCH 0015 / 0100 | BATCH 0001 / 0012 | LOSS 0.1785\n",
      "TRAIN: EPOCH 0015 / 0100 | BATCH 0002 / 0012 | LOSS 0.1997\n",
      "TRAIN: EPOCH 0015 / 0100 | BATCH 0003 / 0012 | LOSS 0.1963\n",
      "TRAIN: EPOCH 0015 / 0100 | BATCH 0004 / 0012 | LOSS 0.2034\n",
      "TRAIN: EPOCH 0015 / 0100 | BATCH 0005 / 0012 | LOSS 0.2042\n",
      "TRAIN: EPOCH 0015 / 0100 | BATCH 0006 / 0012 | LOSS 0.2030\n",
      "TRAIN: EPOCH 0015 / 0100 | BATCH 0007 / 0012 | LOSS 0.2038\n",
      "TRAIN: EPOCH 0015 / 0100 | BATCH 0008 / 0012 | LOSS 0.2044\n",
      "TRAIN: EPOCH 0015 / 0100 | BATCH 0009 / 0012 | LOSS 0.2039\n",
      "TRAIN: EPOCH 0015 / 0100 | BATCH 0010 / 0012 | LOSS 0.2013\n",
      "TRAIN: EPOCH 0015 / 0100 | BATCH 0011 / 0012 | LOSS 0.2012\n",
      "TRAIN: EPOCH 0015 / 0100 | BATCH 0012 / 0012 | LOSS 0.2003\n",
      "VALID: EPOCH 0015 / 0100 | BATCH 0001 / 0002 | LOSS 0.2022\n",
      "VALID: EPOCH 0015 / 0100 | BATCH 0002 / 0002 | LOSS 0.2116\n",
      "TRAIN: EPOCH 0016 / 0100 | BATCH 0001 / 0012 | LOSS 0.1794\n",
      "TRAIN: EPOCH 0016 / 0100 | BATCH 0002 / 0012 | LOSS 0.1934\n",
      "TRAIN: EPOCH 0016 / 0100 | BATCH 0003 / 0012 | LOSS 0.1941\n",
      "TRAIN: EPOCH 0016 / 0100 | BATCH 0004 / 0012 | LOSS 0.1977\n",
      "TRAIN: EPOCH 0016 / 0100 | BATCH 0005 / 0012 | LOSS 0.2005\n",
      "TRAIN: EPOCH 0016 / 0100 | BATCH 0006 / 0012 | LOSS 0.1990\n",
      "TRAIN: EPOCH 0016 / 0100 | BATCH 0007 / 0012 | LOSS 0.1989\n",
      "TRAIN: EPOCH 0016 / 0100 | BATCH 0008 / 0012 | LOSS 0.2002\n",
      "TRAIN: EPOCH 0016 / 0100 | BATCH 0009 / 0012 | LOSS 0.1987\n",
      "TRAIN: EPOCH 0016 / 0100 | BATCH 0010 / 0012 | LOSS 0.1982\n",
      "TRAIN: EPOCH 0016 / 0100 | BATCH 0011 / 0012 | LOSS 0.1982\n",
      "TRAIN: EPOCH 0016 / 0100 | BATCH 0012 / 0012 | LOSS 0.1966\n",
      "VALID: EPOCH 0016 / 0100 | BATCH 0001 / 0002 | LOSS 0.1919\n",
      "VALID: EPOCH 0016 / 0100 | BATCH 0002 / 0002 | LOSS 0.2126\n",
      "TRAIN: EPOCH 0017 / 0100 | BATCH 0001 / 0012 | LOSS 0.2048\n",
      "TRAIN: EPOCH 0017 / 0100 | BATCH 0002 / 0012 | LOSS 0.2019\n",
      "TRAIN: EPOCH 0017 / 0100 | BATCH 0003 / 0012 | LOSS 0.2018\n",
      "TRAIN: EPOCH 0017 / 0100 | BATCH 0004 / 0012 | LOSS 0.2072\n",
      "TRAIN: EPOCH 0017 / 0100 | BATCH 0005 / 0012 | LOSS 0.2044\n",
      "TRAIN: EPOCH 0017 / 0100 | BATCH 0006 / 0012 | LOSS 0.2013\n",
      "TRAIN: EPOCH 0017 / 0100 | BATCH 0007 / 0012 | LOSS 0.1993\n",
      "TRAIN: EPOCH 0017 / 0100 | BATCH 0008 / 0012 | LOSS 0.1997\n",
      "TRAIN: EPOCH 0017 / 0100 | BATCH 0009 / 0012 | LOSS 0.1971\n",
      "TRAIN: EPOCH 0017 / 0100 | BATCH 0010 / 0012 | LOSS 0.1963\n",
      "TRAIN: EPOCH 0017 / 0100 | BATCH 0011 / 0012 | LOSS 0.1961\n",
      "TRAIN: EPOCH 0017 / 0100 | BATCH 0012 / 0012 | LOSS 0.1969\n",
      "VALID: EPOCH 0017 / 0100 | BATCH 0001 / 0002 | LOSS 0.1926\n",
      "VALID: EPOCH 0017 / 0100 | BATCH 0002 / 0002 | LOSS 0.2063\n",
      "TRAIN: EPOCH 0018 / 0100 | BATCH 0001 / 0012 | LOSS 0.1976\n",
      "TRAIN: EPOCH 0018 / 0100 | BATCH 0002 / 0012 | LOSS 0.1893\n",
      "TRAIN: EPOCH 0018 / 0100 | BATCH 0003 / 0012 | LOSS 0.1907\n",
      "TRAIN: EPOCH 0018 / 0100 | BATCH 0004 / 0012 | LOSS 0.1948\n",
      "TRAIN: EPOCH 0018 / 0100 | BATCH 0005 / 0012 | LOSS 0.1918\n",
      "TRAIN: EPOCH 0018 / 0100 | BATCH 0006 / 0012 | LOSS 0.1937\n",
      "TRAIN: EPOCH 0018 / 0100 | BATCH 0007 / 0012 | LOSS 0.1956\n",
      "TRAIN: EPOCH 0018 / 0100 | BATCH 0008 / 0012 | LOSS 0.1946\n",
      "TRAIN: EPOCH 0018 / 0100 | BATCH 0009 / 0012 | LOSS 0.1970\n",
      "TRAIN: EPOCH 0018 / 0100 | BATCH 0010 / 0012 | LOSS 0.1982\n",
      "TRAIN: EPOCH 0018 / 0100 | BATCH 0011 / 0012 | LOSS 0.1997\n",
      "TRAIN: EPOCH 0018 / 0100 | BATCH 0012 / 0012 | LOSS 0.1989\n",
      "VALID: EPOCH 0018 / 0100 | BATCH 0001 / 0002 | LOSS 0.1941\n",
      "VALID: EPOCH 0018 / 0100 | BATCH 0002 / 0002 | LOSS 0.2108\n",
      "TRAIN: EPOCH 0019 / 0100 | BATCH 0001 / 0012 | LOSS 0.1751\n",
      "TRAIN: EPOCH 0019 / 0100 | BATCH 0002 / 0012 | LOSS 0.1822\n",
      "TRAIN: EPOCH 0019 / 0100 | BATCH 0003 / 0012 | LOSS 0.1790\n",
      "TRAIN: EPOCH 0019 / 0100 | BATCH 0004 / 0012 | LOSS 0.1785\n",
      "TRAIN: EPOCH 0019 / 0100 | BATCH 0005 / 0012 | LOSS 0.1857\n",
      "TRAIN: EPOCH 0019 / 0100 | BATCH 0006 / 0012 | LOSS 0.1900\n",
      "TRAIN: EPOCH 0019 / 0100 | BATCH 0007 / 0012 | LOSS 0.1917\n",
      "TRAIN: EPOCH 0019 / 0100 | BATCH 0008 / 0012 | LOSS 0.1902\n",
      "TRAIN: EPOCH 0019 / 0100 | BATCH 0009 / 0012 | LOSS 0.1917\n",
      "TRAIN: EPOCH 0019 / 0100 | BATCH 0010 / 0012 | LOSS 0.1945\n",
      "TRAIN: EPOCH 0019 / 0100 | BATCH 0011 / 0012 | LOSS 0.1943\n",
      "TRAIN: EPOCH 0019 / 0100 | BATCH 0012 / 0012 | LOSS 0.1945\n",
      "VALID: EPOCH 0019 / 0100 | BATCH 0001 / 0002 | LOSS 0.2389\n",
      "VALID: EPOCH 0019 / 0100 | BATCH 0002 / 0002 | LOSS 0.2450\n",
      "TRAIN: EPOCH 0020 / 0100 | BATCH 0001 / 0012 | LOSS 0.1872\n",
      "TRAIN: EPOCH 0020 / 0100 | BATCH 0002 / 0012 | LOSS 0.1939\n",
      "TRAIN: EPOCH 0020 / 0100 | BATCH 0003 / 0012 | LOSS 0.1928\n",
      "TRAIN: EPOCH 0020 / 0100 | BATCH 0004 / 0012 | LOSS 0.1912\n",
      "TRAIN: EPOCH 0020 / 0100 | BATCH 0005 / 0012 | LOSS 0.1860\n",
      "TRAIN: EPOCH 0020 / 0100 | BATCH 0006 / 0012 | LOSS 0.1859\n",
      "TRAIN: EPOCH 0020 / 0100 | BATCH 0007 / 0012 | LOSS 0.1860\n",
      "TRAIN: EPOCH 0020 / 0100 | BATCH 0008 / 0012 | LOSS 0.1895\n",
      "TRAIN: EPOCH 0020 / 0100 | BATCH 0009 / 0012 | LOSS 0.1979\n",
      "TRAIN: EPOCH 0020 / 0100 | BATCH 0010 / 0012 | LOSS 0.1956\n",
      "TRAIN: EPOCH 0020 / 0100 | BATCH 0011 / 0012 | LOSS 0.1950\n",
      "TRAIN: EPOCH 0020 / 0100 | BATCH 0012 / 0012 | LOSS 0.1968\n",
      "VALID: EPOCH 0020 / 0100 | BATCH 0001 / 0002 | LOSS 0.1867\n",
      "VALID: EPOCH 0020 / 0100 | BATCH 0002 / 0002 | LOSS 0.2056\n",
      "TRAIN: EPOCH 0021 / 0100 | BATCH 0001 / 0012 | LOSS 0.1846\n",
      "TRAIN: EPOCH 0021 / 0100 | BATCH 0002 / 0012 | LOSS 0.1855\n",
      "TRAIN: EPOCH 0021 / 0100 | BATCH 0003 / 0012 | LOSS 0.1835\n",
      "TRAIN: EPOCH 0021 / 0100 | BATCH 0004 / 0012 | LOSS 0.1886\n",
      "TRAIN: EPOCH 0021 / 0100 | BATCH 0005 / 0012 | LOSS 0.1912\n",
      "TRAIN: EPOCH 0021 / 0100 | BATCH 0006 / 0012 | LOSS 0.1938\n",
      "TRAIN: EPOCH 0021 / 0100 | BATCH 0007 / 0012 | LOSS 0.1958\n",
      "TRAIN: EPOCH 0021 / 0100 | BATCH 0008 / 0012 | LOSS 0.1957\n",
      "TRAIN: EPOCH 0021 / 0100 | BATCH 0009 / 0012 | LOSS 0.1977\n",
      "TRAIN: EPOCH 0021 / 0100 | BATCH 0010 / 0012 | LOSS 0.1969\n",
      "TRAIN: EPOCH 0021 / 0100 | BATCH 0011 / 0012 | LOSS 0.1983\n",
      "TRAIN: EPOCH 0021 / 0100 | BATCH 0012 / 0012 | LOSS 0.1960\n",
      "VALID: EPOCH 0021 / 0100 | BATCH 0001 / 0002 | LOSS 0.1885\n",
      "VALID: EPOCH 0021 / 0100 | BATCH 0002 / 0002 | LOSS 0.2048\n",
      "TRAIN: EPOCH 0022 / 0100 | BATCH 0001 / 0012 | LOSS 0.2072\n",
      "TRAIN: EPOCH 0022 / 0100 | BATCH 0002 / 0012 | LOSS 0.1931\n",
      "TRAIN: EPOCH 0022 / 0100 | BATCH 0003 / 0012 | LOSS 0.1884\n",
      "TRAIN: EPOCH 0022 / 0100 | BATCH 0004 / 0012 | LOSS 0.1884\n",
      "TRAIN: EPOCH 0022 / 0100 | BATCH 0005 / 0012 | LOSS 0.1885\n",
      "TRAIN: EPOCH 0022 / 0100 | BATCH 0006 / 0012 | LOSS 0.1884\n",
      "TRAIN: EPOCH 0022 / 0100 | BATCH 0007 / 0012 | LOSS 0.1854\n",
      "TRAIN: EPOCH 0022 / 0100 | BATCH 0008 / 0012 | LOSS 0.1851\n",
      "TRAIN: EPOCH 0022 / 0100 | BATCH 0009 / 0012 | LOSS 0.1867\n",
      "TRAIN: EPOCH 0022 / 0100 | BATCH 0010 / 0012 | LOSS 0.1871\n",
      "TRAIN: EPOCH 0022 / 0100 | BATCH 0011 / 0012 | LOSS 0.1909\n",
      "TRAIN: EPOCH 0022 / 0100 | BATCH 0012 / 0012 | LOSS 0.1923\n",
      "VALID: EPOCH 0022 / 0100 | BATCH 0001 / 0002 | LOSS 0.1871\n",
      "VALID: EPOCH 0022 / 0100 | BATCH 0002 / 0002 | LOSS 0.2099\n",
      "TRAIN: EPOCH 0023 / 0100 | BATCH 0001 / 0012 | LOSS 0.2056\n",
      "TRAIN: EPOCH 0023 / 0100 | BATCH 0002 / 0012 | LOSS 0.1940\n",
      "TRAIN: EPOCH 0023 / 0100 | BATCH 0003 / 0012 | LOSS 0.1919\n",
      "TRAIN: EPOCH 0023 / 0100 | BATCH 0004 / 0012 | LOSS 0.1912\n",
      "TRAIN: EPOCH 0023 / 0100 | BATCH 0005 / 0012 | LOSS 0.1879\n",
      "TRAIN: EPOCH 0023 / 0100 | BATCH 0006 / 0012 | LOSS 0.1850\n",
      "TRAIN: EPOCH 0023 / 0100 | BATCH 0007 / 0012 | LOSS 0.1870\n",
      "TRAIN: EPOCH 0023 / 0100 | BATCH 0008 / 0012 | LOSS 0.1929\n",
      "TRAIN: EPOCH 0023 / 0100 | BATCH 0009 / 0012 | LOSS 0.1916\n",
      "TRAIN: EPOCH 0023 / 0100 | BATCH 0010 / 0012 | LOSS 0.1897\n",
      "TRAIN: EPOCH 0023 / 0100 | BATCH 0011 / 0012 | LOSS 0.1900\n",
      "TRAIN: EPOCH 0023 / 0100 | BATCH 0012 / 0012 | LOSS 0.1947\n",
      "VALID: EPOCH 0023 / 0100 | BATCH 0001 / 0002 | LOSS 0.1908\n",
      "VALID: EPOCH 0023 / 0100 | BATCH 0002 / 0002 | LOSS 0.2061\n",
      "TRAIN: EPOCH 0024 / 0100 | BATCH 0001 / 0012 | LOSS 0.1733\n",
      "TRAIN: EPOCH 0024 / 0100 | BATCH 0002 / 0012 | LOSS 0.1782\n",
      "TRAIN: EPOCH 0024 / 0100 | BATCH 0003 / 0012 | LOSS 0.1845\n",
      "TRAIN: EPOCH 0024 / 0100 | BATCH 0004 / 0012 | LOSS 0.1860\n",
      "TRAIN: EPOCH 0024 / 0100 | BATCH 0005 / 0012 | LOSS 0.1831\n",
      "TRAIN: EPOCH 0024 / 0100 | BATCH 0006 / 0012 | LOSS 0.1937\n",
      "TRAIN: EPOCH 0024 / 0100 | BATCH 0007 / 0012 | LOSS 0.1930\n",
      "TRAIN: EPOCH 0024 / 0100 | BATCH 0008 / 0012 | LOSS 0.1912\n",
      "TRAIN: EPOCH 0024 / 0100 | BATCH 0009 / 0012 | LOSS 0.1914\n",
      "TRAIN: EPOCH 0024 / 0100 | BATCH 0010 / 0012 | LOSS 0.1893\n",
      "TRAIN: EPOCH 0024 / 0100 | BATCH 0011 / 0012 | LOSS 0.1891\n",
      "TRAIN: EPOCH 0024 / 0100 | BATCH 0012 / 0012 | LOSS 0.1895\n",
      "VALID: EPOCH 0024 / 0100 | BATCH 0001 / 0002 | LOSS 0.1906\n",
      "VALID: EPOCH 0024 / 0100 | BATCH 0002 / 0002 | LOSS 0.2038\n",
      "TRAIN: EPOCH 0025 / 0100 | BATCH 0001 / 0012 | LOSS 0.1967\n",
      "TRAIN: EPOCH 0025 / 0100 | BATCH 0002 / 0012 | LOSS 0.1986\n",
      "TRAIN: EPOCH 0025 / 0100 | BATCH 0003 / 0012 | LOSS 0.2050\n",
      "TRAIN: EPOCH 0025 / 0100 | BATCH 0004 / 0012 | LOSS 0.2008\n",
      "TRAIN: EPOCH 0025 / 0100 | BATCH 0005 / 0012 | LOSS 0.1936\n",
      "TRAIN: EPOCH 0025 / 0100 | BATCH 0006 / 0012 | LOSS 0.1930\n",
      "TRAIN: EPOCH 0025 / 0100 | BATCH 0007 / 0012 | LOSS 0.1897\n",
      "TRAIN: EPOCH 0025 / 0100 | BATCH 0008 / 0012 | LOSS 0.1905\n",
      "TRAIN: EPOCH 0025 / 0100 | BATCH 0009 / 0012 | LOSS 0.1924\n",
      "TRAIN: EPOCH 0025 / 0100 | BATCH 0010 / 0012 | LOSS 0.1906\n",
      "TRAIN: EPOCH 0025 / 0100 | BATCH 0011 / 0012 | LOSS 0.1889\n",
      "TRAIN: EPOCH 0025 / 0100 | BATCH 0012 / 0012 | LOSS 0.1913\n",
      "VALID: EPOCH 0025 / 0100 | BATCH 0001 / 0002 | LOSS 0.2122\n",
      "VALID: EPOCH 0025 / 0100 | BATCH 0002 / 0002 | LOSS 0.2106\n",
      "TRAIN: EPOCH 0026 / 0100 | BATCH 0001 / 0012 | LOSS 0.1955\n",
      "TRAIN: EPOCH 0026 / 0100 | BATCH 0002 / 0012 | LOSS 0.2035\n",
      "TRAIN: EPOCH 0026 / 0100 | BATCH 0003 / 0012 | LOSS 0.1935\n",
      "TRAIN: EPOCH 0026 / 0100 | BATCH 0004 / 0012 | LOSS 0.1897\n",
      "TRAIN: EPOCH 0026 / 0100 | BATCH 0005 / 0012 | LOSS 0.1872\n",
      "TRAIN: EPOCH 0026 / 0100 | BATCH 0006 / 0012 | LOSS 0.1883\n",
      "TRAIN: EPOCH 0026 / 0100 | BATCH 0007 / 0012 | LOSS 0.1884\n",
      "TRAIN: EPOCH 0026 / 0100 | BATCH 0008 / 0012 | LOSS 0.1871\n",
      "TRAIN: EPOCH 0026 / 0100 | BATCH 0009 / 0012 | LOSS 0.1904\n",
      "TRAIN: EPOCH 0026 / 0100 | BATCH 0010 / 0012 | LOSS 0.1877\n",
      "TRAIN: EPOCH 0026 / 0100 | BATCH 0011 / 0012 | LOSS 0.1873\n",
      "TRAIN: EPOCH 0026 / 0100 | BATCH 0012 / 0012 | LOSS 0.1873\n",
      "VALID: EPOCH 0026 / 0100 | BATCH 0001 / 0002 | LOSS 0.2132\n",
      "VALID: EPOCH 0026 / 0100 | BATCH 0002 / 0002 | LOSS 0.2297\n",
      "TRAIN: EPOCH 0027 / 0100 | BATCH 0001 / 0012 | LOSS 0.1805\n",
      "TRAIN: EPOCH 0027 / 0100 | BATCH 0002 / 0012 | LOSS 0.1834\n",
      "TRAIN: EPOCH 0027 / 0100 | BATCH 0003 / 0012 | LOSS 0.1913\n",
      "TRAIN: EPOCH 0027 / 0100 | BATCH 0004 / 0012 | LOSS 0.1846\n",
      "TRAIN: EPOCH 0027 / 0100 | BATCH 0005 / 0012 | LOSS 0.1833\n",
      "TRAIN: EPOCH 0027 / 0100 | BATCH 0006 / 0012 | LOSS 0.1829\n",
      "TRAIN: EPOCH 0027 / 0100 | BATCH 0007 / 0012 | LOSS 0.1917\n",
      "TRAIN: EPOCH 0027 / 0100 | BATCH 0008 / 0012 | LOSS 0.1921\n",
      "TRAIN: EPOCH 0027 / 0100 | BATCH 0009 / 0012 | LOSS 0.1911\n",
      "TRAIN: EPOCH 0027 / 0100 | BATCH 0010 / 0012 | LOSS 0.1911\n",
      "TRAIN: EPOCH 0027 / 0100 | BATCH 0011 / 0012 | LOSS 0.1889\n",
      "TRAIN: EPOCH 0027 / 0100 | BATCH 0012 / 0012 | LOSS 0.1894\n",
      "VALID: EPOCH 0027 / 0100 | BATCH 0001 / 0002 | LOSS 0.1927\n",
      "VALID: EPOCH 0027 / 0100 | BATCH 0002 / 0002 | LOSS 0.2110\n",
      "TRAIN: EPOCH 0028 / 0100 | BATCH 0001 / 0012 | LOSS 0.2035\n",
      "TRAIN: EPOCH 0028 / 0100 | BATCH 0002 / 0012 | LOSS 0.1824\n",
      "TRAIN: EPOCH 0028 / 0100 | BATCH 0003 / 0012 | LOSS 0.1773\n",
      "TRAIN: EPOCH 0028 / 0100 | BATCH 0004 / 0012 | LOSS 0.1793\n",
      "TRAIN: EPOCH 0028 / 0100 | BATCH 0005 / 0012 | LOSS 0.1822\n",
      "TRAIN: EPOCH 0028 / 0100 | BATCH 0006 / 0012 | LOSS 0.1820\n",
      "TRAIN: EPOCH 0028 / 0100 | BATCH 0007 / 0012 | LOSS 0.1837\n",
      "TRAIN: EPOCH 0028 / 0100 | BATCH 0008 / 0012 | LOSS 0.1846\n",
      "TRAIN: EPOCH 0028 / 0100 | BATCH 0009 / 0012 | LOSS 0.1848\n",
      "TRAIN: EPOCH 0028 / 0100 | BATCH 0010 / 0012 | LOSS 0.1860\n",
      "TRAIN: EPOCH 0028 / 0100 | BATCH 0011 / 0012 | LOSS 0.1855\n",
      "TRAIN: EPOCH 0028 / 0100 | BATCH 0012 / 0012 | LOSS 0.1844\n",
      "VALID: EPOCH 0028 / 0100 | BATCH 0001 / 0002 | LOSS 0.1867\n",
      "VALID: EPOCH 0028 / 0100 | BATCH 0002 / 0002 | LOSS 0.2030\n",
      "TRAIN: EPOCH 0029 / 0100 | BATCH 0001 / 0012 | LOSS 0.1689\n",
      "TRAIN: EPOCH 0029 / 0100 | BATCH 0002 / 0012 | LOSS 0.1766\n",
      "TRAIN: EPOCH 0029 / 0100 | BATCH 0003 / 0012 | LOSS 0.1723\n",
      "TRAIN: EPOCH 0029 / 0100 | BATCH 0004 / 0012 | LOSS 0.1718\n",
      "TRAIN: EPOCH 0029 / 0100 | BATCH 0005 / 0012 | LOSS 0.1776\n",
      "TRAIN: EPOCH 0029 / 0100 | BATCH 0006 / 0012 | LOSS 0.1765\n",
      "TRAIN: EPOCH 0029 / 0100 | BATCH 0007 / 0012 | LOSS 0.1811\n",
      "TRAIN: EPOCH 0029 / 0100 | BATCH 0008 / 0012 | LOSS 0.1822\n",
      "TRAIN: EPOCH 0029 / 0100 | BATCH 0009 / 0012 | LOSS 0.1860\n",
      "TRAIN: EPOCH 0029 / 0100 | BATCH 0010 / 0012 | LOSS 0.1851\n",
      "TRAIN: EPOCH 0029 / 0100 | BATCH 0011 / 0012 | LOSS 0.1861\n",
      "TRAIN: EPOCH 0029 / 0100 | BATCH 0012 / 0012 | LOSS 0.1862\n",
      "VALID: EPOCH 0029 / 0100 | BATCH 0001 / 0002 | LOSS 0.1965\n",
      "VALID: EPOCH 0029 / 0100 | BATCH 0002 / 0002 | LOSS 0.2255\n",
      "TRAIN: EPOCH 0030 / 0100 | BATCH 0001 / 0012 | LOSS 0.1867\n",
      "TRAIN: EPOCH 0030 / 0100 | BATCH 0002 / 0012 | LOSS 0.1989\n",
      "TRAIN: EPOCH 0030 / 0100 | BATCH 0003 / 0012 | LOSS 0.2059\n",
      "TRAIN: EPOCH 0030 / 0100 | BATCH 0004 / 0012 | LOSS 0.1983\n",
      "TRAIN: EPOCH 0030 / 0100 | BATCH 0005 / 0012 | LOSS 0.1933\n",
      "TRAIN: EPOCH 0030 / 0100 | BATCH 0006 / 0012 | LOSS 0.1890\n",
      "TRAIN: EPOCH 0030 / 0100 | BATCH 0007 / 0012 | LOSS 0.1854\n",
      "TRAIN: EPOCH 0030 / 0100 | BATCH 0008 / 0012 | LOSS 0.1847\n",
      "TRAIN: EPOCH 0030 / 0100 | BATCH 0009 / 0012 | LOSS 0.1866\n",
      "TRAIN: EPOCH 0030 / 0100 | BATCH 0010 / 0012 | LOSS 0.1862\n",
      "TRAIN: EPOCH 0030 / 0100 | BATCH 0011 / 0012 | LOSS 0.1845\n",
      "TRAIN: EPOCH 0030 / 0100 | BATCH 0012 / 0012 | LOSS 0.1856\n",
      "VALID: EPOCH 0030 / 0100 | BATCH 0001 / 0002 | LOSS 0.1827\n",
      "VALID: EPOCH 0030 / 0100 | BATCH 0002 / 0002 | LOSS 0.1943\n",
      "TRAIN: EPOCH 0031 / 0100 | BATCH 0001 / 0012 | LOSS 0.1924\n",
      "TRAIN: EPOCH 0031 / 0100 | BATCH 0002 / 0012 | LOSS 0.1708\n",
      "TRAIN: EPOCH 0031 / 0100 | BATCH 0003 / 0012 | LOSS 0.1772\n",
      "TRAIN: EPOCH 0031 / 0100 | BATCH 0004 / 0012 | LOSS 0.1784\n",
      "TRAIN: EPOCH 0031 / 0100 | BATCH 0005 / 0012 | LOSS 0.1781\n",
      "TRAIN: EPOCH 0031 / 0100 | BATCH 0006 / 0012 | LOSS 0.1791\n",
      "TRAIN: EPOCH 0031 / 0100 | BATCH 0007 / 0012 | LOSS 0.1828\n",
      "TRAIN: EPOCH 0031 / 0100 | BATCH 0008 / 0012 | LOSS 0.1823\n",
      "TRAIN: EPOCH 0031 / 0100 | BATCH 0009 / 0012 | LOSS 0.1804\n",
      "TRAIN: EPOCH 0031 / 0100 | BATCH 0010 / 0012 | LOSS 0.1812\n",
      "TRAIN: EPOCH 0031 / 0100 | BATCH 0011 / 0012 | LOSS 0.1798\n",
      "TRAIN: EPOCH 0031 / 0100 | BATCH 0012 / 0012 | LOSS 0.1842\n",
      "VALID: EPOCH 0031 / 0100 | BATCH 0001 / 0002 | LOSS 0.1821\n",
      "VALID: EPOCH 0031 / 0100 | BATCH 0002 / 0002 | LOSS 0.2022\n",
      "TRAIN: EPOCH 0032 / 0100 | BATCH 0001 / 0012 | LOSS 0.1640\n",
      "TRAIN: EPOCH 0032 / 0100 | BATCH 0002 / 0012 | LOSS 0.1693\n",
      "TRAIN: EPOCH 0032 / 0100 | BATCH 0003 / 0012 | LOSS 0.1711\n",
      "TRAIN: EPOCH 0032 / 0100 | BATCH 0004 / 0012 | LOSS 0.1749\n",
      "TRAIN: EPOCH 0032 / 0100 | BATCH 0005 / 0012 | LOSS 0.1784\n",
      "TRAIN: EPOCH 0032 / 0100 | BATCH 0006 / 0012 | LOSS 0.1832\n",
      "TRAIN: EPOCH 0032 / 0100 | BATCH 0007 / 0012 | LOSS 0.1870\n",
      "TRAIN: EPOCH 0032 / 0100 | BATCH 0008 / 0012 | LOSS 0.1847\n",
      "TRAIN: EPOCH 0032 / 0100 | BATCH 0009 / 0012 | LOSS 0.1813\n",
      "TRAIN: EPOCH 0032 / 0100 | BATCH 0010 / 0012 | LOSS 0.1810\n",
      "TRAIN: EPOCH 0032 / 0100 | BATCH 0011 / 0012 | LOSS 0.1809\n",
      "TRAIN: EPOCH 0032 / 0100 | BATCH 0012 / 0012 | LOSS 0.1811\n",
      "VALID: EPOCH 0032 / 0100 | BATCH 0001 / 0002 | LOSS 0.1720\n",
      "VALID: EPOCH 0032 / 0100 | BATCH 0002 / 0002 | LOSS 0.1943\n",
      "TRAIN: EPOCH 0033 / 0100 | BATCH 0001 / 0012 | LOSS 0.1792\n",
      "TRAIN: EPOCH 0033 / 0100 | BATCH 0002 / 0012 | LOSS 0.1954\n",
      "TRAIN: EPOCH 0033 / 0100 | BATCH 0003 / 0012 | LOSS 0.1911\n",
      "TRAIN: EPOCH 0033 / 0100 | BATCH 0004 / 0012 | LOSS 0.1821\n",
      "TRAIN: EPOCH 0033 / 0100 | BATCH 0005 / 0012 | LOSS 0.1793\n",
      "TRAIN: EPOCH 0033 / 0100 | BATCH 0006 / 0012 | LOSS 0.1771\n",
      "TRAIN: EPOCH 0033 / 0100 | BATCH 0007 / 0012 | LOSS 0.1834\n",
      "TRAIN: EPOCH 0033 / 0100 | BATCH 0008 / 0012 | LOSS 0.1814\n",
      "TRAIN: EPOCH 0033 / 0100 | BATCH 0009 / 0012 | LOSS 0.1799\n",
      "TRAIN: EPOCH 0033 / 0100 | BATCH 0010 / 0012 | LOSS 0.1795\n",
      "TRAIN: EPOCH 0033 / 0100 | BATCH 0011 / 0012 | LOSS 0.1814\n",
      "TRAIN: EPOCH 0033 / 0100 | BATCH 0012 / 0012 | LOSS 0.1827\n",
      "VALID: EPOCH 0033 / 0100 | BATCH 0001 / 0002 | LOSS 0.1944\n",
      "VALID: EPOCH 0033 / 0100 | BATCH 0002 / 0002 | LOSS 0.2013\n",
      "TRAIN: EPOCH 0034 / 0100 | BATCH 0001 / 0012 | LOSS 0.2013\n",
      "TRAIN: EPOCH 0034 / 0100 | BATCH 0002 / 0012 | LOSS 0.1823\n",
      "TRAIN: EPOCH 0034 / 0100 | BATCH 0003 / 0012 | LOSS 0.1785\n",
      "TRAIN: EPOCH 0034 / 0100 | BATCH 0004 / 0012 | LOSS 0.1824\n",
      "TRAIN: EPOCH 0034 / 0100 | BATCH 0005 / 0012 | LOSS 0.1781\n",
      "TRAIN: EPOCH 0034 / 0100 | BATCH 0006 / 0012 | LOSS 0.1774\n",
      "TRAIN: EPOCH 0034 / 0100 | BATCH 0007 / 0012 | LOSS 0.1852\n",
      "TRAIN: EPOCH 0034 / 0100 | BATCH 0008 / 0012 | LOSS 0.1836\n",
      "TRAIN: EPOCH 0034 / 0100 | BATCH 0009 / 0012 | LOSS 0.1849\n",
      "TRAIN: EPOCH 0034 / 0100 | BATCH 0010 / 0012 | LOSS 0.1849\n",
      "TRAIN: EPOCH 0034 / 0100 | BATCH 0011 / 0012 | LOSS 0.1851\n",
      "TRAIN: EPOCH 0034 / 0100 | BATCH 0012 / 0012 | LOSS 0.1856\n",
      "VALID: EPOCH 0034 / 0100 | BATCH 0001 / 0002 | LOSS 0.2006\n",
      "VALID: EPOCH 0034 / 0100 | BATCH 0002 / 0002 | LOSS 0.2221\n",
      "TRAIN: EPOCH 0035 / 0100 | BATCH 0001 / 0012 | LOSS 0.1908\n",
      "TRAIN: EPOCH 0035 / 0100 | BATCH 0002 / 0012 | LOSS 0.1902\n",
      "TRAIN: EPOCH 0035 / 0100 | BATCH 0003 / 0012 | LOSS 0.1909\n",
      "TRAIN: EPOCH 0035 / 0100 | BATCH 0004 / 0012 | LOSS 0.1890\n",
      "TRAIN: EPOCH 0035 / 0100 | BATCH 0005 / 0012 | LOSS 0.1859\n",
      "TRAIN: EPOCH 0035 / 0100 | BATCH 0006 / 0012 | LOSS 0.1842\n",
      "TRAIN: EPOCH 0035 / 0100 | BATCH 0007 / 0012 | LOSS 0.1851\n",
      "TRAIN: EPOCH 0035 / 0100 | BATCH 0008 / 0012 | LOSS 0.1841\n",
      "TRAIN: EPOCH 0035 / 0100 | BATCH 0009 / 0012 | LOSS 0.1815\n",
      "TRAIN: EPOCH 0035 / 0100 | BATCH 0010 / 0012 | LOSS 0.1848\n",
      "TRAIN: EPOCH 0035 / 0100 | BATCH 0011 / 0012 | LOSS 0.1835\n",
      "TRAIN: EPOCH 0035 / 0100 | BATCH 0012 / 0012 | LOSS 0.1823\n",
      "VALID: EPOCH 0035 / 0100 | BATCH 0001 / 0002 | LOSS 0.1867\n",
      "VALID: EPOCH 0035 / 0100 | BATCH 0002 / 0002 | LOSS 0.2131\n",
      "TRAIN: EPOCH 0036 / 0100 | BATCH 0001 / 0012 | LOSS 0.2271\n",
      "TRAIN: EPOCH 0036 / 0100 | BATCH 0002 / 0012 | LOSS 0.2031\n",
      "TRAIN: EPOCH 0036 / 0100 | BATCH 0003 / 0012 | LOSS 0.1906\n",
      "TRAIN: EPOCH 0036 / 0100 | BATCH 0004 / 0012 | LOSS 0.1863\n",
      "TRAIN: EPOCH 0036 / 0100 | BATCH 0005 / 0012 | LOSS 0.1840\n",
      "TRAIN: EPOCH 0036 / 0100 | BATCH 0006 / 0012 | LOSS 0.1795\n",
      "TRAIN: EPOCH 0036 / 0100 | BATCH 0007 / 0012 | LOSS 0.1778\n",
      "TRAIN: EPOCH 0036 / 0100 | BATCH 0008 / 0012 | LOSS 0.1839\n",
      "TRAIN: EPOCH 0036 / 0100 | BATCH 0009 / 0012 | LOSS 0.1837\n",
      "TRAIN: EPOCH 0036 / 0100 | BATCH 0010 / 0012 | LOSS 0.1821\n",
      "TRAIN: EPOCH 0036 / 0100 | BATCH 0011 / 0012 | LOSS 0.1824\n",
      "TRAIN: EPOCH 0036 / 0100 | BATCH 0012 / 0012 | LOSS 0.1820\n",
      "VALID: EPOCH 0036 / 0100 | BATCH 0001 / 0002 | LOSS 0.1973\n",
      "VALID: EPOCH 0036 / 0100 | BATCH 0002 / 0002 | LOSS 0.2139\n",
      "TRAIN: EPOCH 0037 / 0100 | BATCH 0001 / 0012 | LOSS 0.1701\n",
      "TRAIN: EPOCH 0037 / 0100 | BATCH 0002 / 0012 | LOSS 0.1649\n",
      "TRAIN: EPOCH 0037 / 0100 | BATCH 0003 / 0012 | LOSS 0.1651\n",
      "TRAIN: EPOCH 0037 / 0100 | BATCH 0004 / 0012 | LOSS 0.1746\n",
      "TRAIN: EPOCH 0037 / 0100 | BATCH 0005 / 0012 | LOSS 0.1727\n",
      "TRAIN: EPOCH 0037 / 0100 | BATCH 0006 / 0012 | LOSS 0.1727\n",
      "TRAIN: EPOCH 0037 / 0100 | BATCH 0007 / 0012 | LOSS 0.1703\n",
      "TRAIN: EPOCH 0037 / 0100 | BATCH 0008 / 0012 | LOSS 0.1717\n",
      "TRAIN: EPOCH 0037 / 0100 | BATCH 0009 / 0012 | LOSS 0.1727\n",
      "TRAIN: EPOCH 0037 / 0100 | BATCH 0010 / 0012 | LOSS 0.1740\n",
      "TRAIN: EPOCH 0037 / 0100 | BATCH 0011 / 0012 | LOSS 0.1733\n",
      "TRAIN: EPOCH 0037 / 0100 | BATCH 0012 / 0012 | LOSS 0.1757\n",
      "VALID: EPOCH 0037 / 0100 | BATCH 0001 / 0002 | LOSS 0.1782\n",
      "VALID: EPOCH 0037 / 0100 | BATCH 0002 / 0002 | LOSS 0.1992\n",
      "TRAIN: EPOCH 0038 / 0100 | BATCH 0001 / 0012 | LOSS 0.1522\n",
      "TRAIN: EPOCH 0038 / 0100 | BATCH 0002 / 0012 | LOSS 0.1703\n",
      "TRAIN: EPOCH 0038 / 0100 | BATCH 0003 / 0012 | LOSS 0.1862\n",
      "TRAIN: EPOCH 0038 / 0100 | BATCH 0004 / 0012 | LOSS 0.1803\n",
      "TRAIN: EPOCH 0038 / 0100 | BATCH 0005 / 0012 | LOSS 0.1775\n",
      "TRAIN: EPOCH 0038 / 0100 | BATCH 0006 / 0012 | LOSS 0.1777\n",
      "TRAIN: EPOCH 0038 / 0100 | BATCH 0007 / 0012 | LOSS 0.1756\n",
      "TRAIN: EPOCH 0038 / 0100 | BATCH 0008 / 0012 | LOSS 0.1750\n",
      "TRAIN: EPOCH 0038 / 0100 | BATCH 0009 / 0012 | LOSS 0.1749\n",
      "TRAIN: EPOCH 0038 / 0100 | BATCH 0010 / 0012 | LOSS 0.1766\n",
      "TRAIN: EPOCH 0038 / 0100 | BATCH 0011 / 0012 | LOSS 0.1804\n",
      "TRAIN: EPOCH 0038 / 0100 | BATCH 0012 / 0012 | LOSS 0.1798\n",
      "VALID: EPOCH 0038 / 0100 | BATCH 0001 / 0002 | LOSS 0.1854\n",
      "VALID: EPOCH 0038 / 0100 | BATCH 0002 / 0002 | LOSS 0.1980\n",
      "TRAIN: EPOCH 0039 / 0100 | BATCH 0001 / 0012 | LOSS 0.1447\n",
      "TRAIN: EPOCH 0039 / 0100 | BATCH 0002 / 0012 | LOSS 0.1511\n",
      "TRAIN: EPOCH 0039 / 0100 | BATCH 0003 / 0012 | LOSS 0.1538\n",
      "TRAIN: EPOCH 0039 / 0100 | BATCH 0004 / 0012 | LOSS 0.1600\n",
      "TRAIN: EPOCH 0039 / 0100 | BATCH 0005 / 0012 | LOSS 0.1674\n",
      "TRAIN: EPOCH 0039 / 0100 | BATCH 0006 / 0012 | LOSS 0.1660\n",
      "TRAIN: EPOCH 0039 / 0100 | BATCH 0007 / 0012 | LOSS 0.1720\n",
      "TRAIN: EPOCH 0039 / 0100 | BATCH 0008 / 0012 | LOSS 0.1748\n",
      "TRAIN: EPOCH 0039 / 0100 | BATCH 0009 / 0012 | LOSS 0.1756\n",
      "TRAIN: EPOCH 0039 / 0100 | BATCH 0010 / 0012 | LOSS 0.1759\n",
      "TRAIN: EPOCH 0039 / 0100 | BATCH 0011 / 0012 | LOSS 0.1759\n",
      "TRAIN: EPOCH 0039 / 0100 | BATCH 0012 / 0012 | LOSS 0.1753\n",
      "VALID: EPOCH 0039 / 0100 | BATCH 0001 / 0002 | LOSS 0.1822\n",
      "VALID: EPOCH 0039 / 0100 | BATCH 0002 / 0002 | LOSS 0.2010\n",
      "TRAIN: EPOCH 0040 / 0100 | BATCH 0001 / 0012 | LOSS 0.1723\n",
      "TRAIN: EPOCH 0040 / 0100 | BATCH 0002 / 0012 | LOSS 0.1707\n",
      "TRAIN: EPOCH 0040 / 0100 | BATCH 0003 / 0012 | LOSS 0.1702\n",
      "TRAIN: EPOCH 0040 / 0100 | BATCH 0004 / 0012 | LOSS 0.1698\n",
      "TRAIN: EPOCH 0040 / 0100 | BATCH 0005 / 0012 | LOSS 0.1727\n",
      "TRAIN: EPOCH 0040 / 0100 | BATCH 0006 / 0012 | LOSS 0.1693\n",
      "TRAIN: EPOCH 0040 / 0100 | BATCH 0007 / 0012 | LOSS 0.1697\n",
      "TRAIN: EPOCH 0040 / 0100 | BATCH 0008 / 0012 | LOSS 0.1699\n",
      "TRAIN: EPOCH 0040 / 0100 | BATCH 0009 / 0012 | LOSS 0.1728\n",
      "TRAIN: EPOCH 0040 / 0100 | BATCH 0010 / 0012 | LOSS 0.1711\n",
      "TRAIN: EPOCH 0040 / 0100 | BATCH 0011 / 0012 | LOSS 0.1746\n",
      "TRAIN: EPOCH 0040 / 0100 | BATCH 0012 / 0012 | LOSS 0.1771\n",
      "VALID: EPOCH 0040 / 0100 | BATCH 0001 / 0002 | LOSS 0.1942\n",
      "VALID: EPOCH 0040 / 0100 | BATCH 0002 / 0002 | LOSS 0.2094\n",
      "TRAIN: EPOCH 0041 / 0100 | BATCH 0001 / 0012 | LOSS 0.1683\n",
      "TRAIN: EPOCH 0041 / 0100 | BATCH 0002 / 0012 | LOSS 0.1732\n",
      "TRAIN: EPOCH 0041 / 0100 | BATCH 0003 / 0012 | LOSS 0.1678\n",
      "TRAIN: EPOCH 0041 / 0100 | BATCH 0004 / 0012 | LOSS 0.1703\n",
      "TRAIN: EPOCH 0041 / 0100 | BATCH 0005 / 0012 | LOSS 0.1741\n",
      "TRAIN: EPOCH 0041 / 0100 | BATCH 0006 / 0012 | LOSS 0.1789\n",
      "TRAIN: EPOCH 0041 / 0100 | BATCH 0007 / 0012 | LOSS 0.1816\n",
      "TRAIN: EPOCH 0041 / 0100 | BATCH 0008 / 0012 | LOSS 0.1813\n",
      "TRAIN: EPOCH 0041 / 0100 | BATCH 0009 / 0012 | LOSS 0.1814\n",
      "TRAIN: EPOCH 0041 / 0100 | BATCH 0010 / 0012 | LOSS 0.1800\n",
      "TRAIN: EPOCH 0041 / 0100 | BATCH 0011 / 0012 | LOSS 0.1804\n",
      "TRAIN: EPOCH 0041 / 0100 | BATCH 0012 / 0012 | LOSS 0.1785\n",
      "VALID: EPOCH 0041 / 0100 | BATCH 0001 / 0002 | LOSS 0.1857\n",
      "VALID: EPOCH 0041 / 0100 | BATCH 0002 / 0002 | LOSS 0.2030\n",
      "TRAIN: EPOCH 0042 / 0100 | BATCH 0001 / 0012 | LOSS 0.1819\n",
      "TRAIN: EPOCH 0042 / 0100 | BATCH 0002 / 0012 | LOSS 0.1803\n",
      "TRAIN: EPOCH 0042 / 0100 | BATCH 0003 / 0012 | LOSS 0.1754\n",
      "TRAIN: EPOCH 0042 / 0100 | BATCH 0004 / 0012 | LOSS 0.1812\n",
      "TRAIN: EPOCH 0042 / 0100 | BATCH 0005 / 0012 | LOSS 0.1789\n",
      "TRAIN: EPOCH 0042 / 0100 | BATCH 0006 / 0012 | LOSS 0.1772\n",
      "TRAIN: EPOCH 0042 / 0100 | BATCH 0007 / 0012 | LOSS 0.1769\n",
      "TRAIN: EPOCH 0042 / 0100 | BATCH 0008 / 0012 | LOSS 0.1744\n",
      "TRAIN: EPOCH 0042 / 0100 | BATCH 0009 / 0012 | LOSS 0.1730\n",
      "TRAIN: EPOCH 0042 / 0100 | BATCH 0010 / 0012 | LOSS 0.1730\n",
      "TRAIN: EPOCH 0042 / 0100 | BATCH 0011 / 0012 | LOSS 0.1726\n",
      "TRAIN: EPOCH 0042 / 0100 | BATCH 0012 / 0012 | LOSS 0.1706\n",
      "VALID: EPOCH 0042 / 0100 | BATCH 0001 / 0002 | LOSS 0.1848\n",
      "VALID: EPOCH 0042 / 0100 | BATCH 0002 / 0002 | LOSS 0.2070\n",
      "TRAIN: EPOCH 0043 / 0100 | BATCH 0001 / 0012 | LOSS 0.1678\n",
      "TRAIN: EPOCH 0043 / 0100 | BATCH 0002 / 0012 | LOSS 0.1614\n",
      "TRAIN: EPOCH 0043 / 0100 | BATCH 0003 / 0012 | LOSS 0.1764\n",
      "TRAIN: EPOCH 0043 / 0100 | BATCH 0004 / 0012 | LOSS 0.1714\n",
      "TRAIN: EPOCH 0043 / 0100 | BATCH 0005 / 0012 | LOSS 0.1716\n",
      "TRAIN: EPOCH 0043 / 0100 | BATCH 0006 / 0012 | LOSS 0.1737\n",
      "TRAIN: EPOCH 0043 / 0100 | BATCH 0007 / 0012 | LOSS 0.1752\n",
      "TRAIN: EPOCH 0043 / 0100 | BATCH 0008 / 0012 | LOSS 0.1773\n",
      "TRAIN: EPOCH 0043 / 0100 | BATCH 0009 / 0012 | LOSS 0.1798\n",
      "TRAIN: EPOCH 0043 / 0100 | BATCH 0010 / 0012 | LOSS 0.1810\n",
      "TRAIN: EPOCH 0043 / 0100 | BATCH 0011 / 0012 | LOSS 0.1797\n",
      "TRAIN: EPOCH 0043 / 0100 | BATCH 0012 / 0012 | LOSS 0.1792\n",
      "VALID: EPOCH 0043 / 0100 | BATCH 0001 / 0002 | LOSS 0.2205\n",
      "VALID: EPOCH 0043 / 0100 | BATCH 0002 / 0002 | LOSS 0.2254\n",
      "TRAIN: EPOCH 0044 / 0100 | BATCH 0001 / 0012 | LOSS 0.1918\n",
      "TRAIN: EPOCH 0044 / 0100 | BATCH 0002 / 0012 | LOSS 0.1834\n",
      "TRAIN: EPOCH 0044 / 0100 | BATCH 0003 / 0012 | LOSS 0.1759\n",
      "TRAIN: EPOCH 0044 / 0100 | BATCH 0004 / 0012 | LOSS 0.1785\n",
      "TRAIN: EPOCH 0044 / 0100 | BATCH 0005 / 0012 | LOSS 0.1721\n",
      "TRAIN: EPOCH 0044 / 0100 | BATCH 0006 / 0012 | LOSS 0.1741\n",
      "TRAIN: EPOCH 0044 / 0100 | BATCH 0007 / 0012 | LOSS 0.1751\n",
      "TRAIN: EPOCH 0044 / 0100 | BATCH 0008 / 0012 | LOSS 0.1738\n",
      "TRAIN: EPOCH 0044 / 0100 | BATCH 0009 / 0012 | LOSS 0.1744\n",
      "TRAIN: EPOCH 0044 / 0100 | BATCH 0010 / 0012 | LOSS 0.1789\n",
      "TRAIN: EPOCH 0044 / 0100 | BATCH 0011 / 0012 | LOSS 0.1795\n",
      "TRAIN: EPOCH 0044 / 0100 | BATCH 0012 / 0012 | LOSS 0.1776\n",
      "VALID: EPOCH 0044 / 0100 | BATCH 0001 / 0002 | LOSS 0.1795\n",
      "VALID: EPOCH 0044 / 0100 | BATCH 0002 / 0002 | LOSS 0.2096\n",
      "TRAIN: EPOCH 0045 / 0100 | BATCH 0001 / 0012 | LOSS 0.1681\n",
      "TRAIN: EPOCH 0045 / 0100 | BATCH 0002 / 0012 | LOSS 0.1770\n",
      "TRAIN: EPOCH 0045 / 0100 | BATCH 0003 / 0012 | LOSS 0.1747\n",
      "TRAIN: EPOCH 0045 / 0100 | BATCH 0004 / 0012 | LOSS 0.1756\n",
      "TRAIN: EPOCH 0045 / 0100 | BATCH 0005 / 0012 | LOSS 0.1749\n",
      "TRAIN: EPOCH 0045 / 0100 | BATCH 0006 / 0012 | LOSS 0.1783\n",
      "TRAIN: EPOCH 0045 / 0100 | BATCH 0007 / 0012 | LOSS 0.1788\n",
      "TRAIN: EPOCH 0045 / 0100 | BATCH 0008 / 0012 | LOSS 0.1784\n",
      "TRAIN: EPOCH 0045 / 0100 | BATCH 0009 / 0012 | LOSS 0.1761\n",
      "TRAIN: EPOCH 0045 / 0100 | BATCH 0010 / 0012 | LOSS 0.1745\n",
      "TRAIN: EPOCH 0045 / 0100 | BATCH 0011 / 0012 | LOSS 0.1756\n",
      "TRAIN: EPOCH 0045 / 0100 | BATCH 0012 / 0012 | LOSS 0.1752\n",
      "VALID: EPOCH 0045 / 0100 | BATCH 0001 / 0002 | LOSS 0.1858\n",
      "VALID: EPOCH 0045 / 0100 | BATCH 0002 / 0002 | LOSS 0.2026\n",
      "TRAIN: EPOCH 0046 / 0100 | BATCH 0001 / 0012 | LOSS 0.1537\n",
      "TRAIN: EPOCH 0046 / 0100 | BATCH 0002 / 0012 | LOSS 0.1561\n",
      "TRAIN: EPOCH 0046 / 0100 | BATCH 0003 / 0012 | LOSS 0.1710\n",
      "TRAIN: EPOCH 0046 / 0100 | BATCH 0004 / 0012 | LOSS 0.1814\n",
      "TRAIN: EPOCH 0046 / 0100 | BATCH 0005 / 0012 | LOSS 0.1826\n",
      "TRAIN: EPOCH 0046 / 0100 | BATCH 0006 / 0012 | LOSS 0.1881\n",
      "TRAIN: EPOCH 0046 / 0100 | BATCH 0007 / 0012 | LOSS 0.1858\n",
      "TRAIN: EPOCH 0046 / 0100 | BATCH 0008 / 0012 | LOSS 0.1851\n",
      "TRAIN: EPOCH 0046 / 0100 | BATCH 0009 / 0012 | LOSS 0.1831\n",
      "TRAIN: EPOCH 0046 / 0100 | BATCH 0010 / 0012 | LOSS 0.1828\n",
      "TRAIN: EPOCH 0046 / 0100 | BATCH 0011 / 0012 | LOSS 0.1808\n",
      "TRAIN: EPOCH 0046 / 0100 | BATCH 0012 / 0012 | LOSS 0.1804\n",
      "VALID: EPOCH 0046 / 0100 | BATCH 0001 / 0002 | LOSS 0.1993\n",
      "VALID: EPOCH 0046 / 0100 | BATCH 0002 / 0002 | LOSS 0.2077\n",
      "TRAIN: EPOCH 0047 / 0100 | BATCH 0001 / 0012 | LOSS 0.1603\n",
      "TRAIN: EPOCH 0047 / 0100 | BATCH 0002 / 0012 | LOSS 0.1609\n",
      "TRAIN: EPOCH 0047 / 0100 | BATCH 0003 / 0012 | LOSS 0.1647\n",
      "TRAIN: EPOCH 0047 / 0100 | BATCH 0004 / 0012 | LOSS 0.1623\n",
      "TRAIN: EPOCH 0047 / 0100 | BATCH 0005 / 0012 | LOSS 0.1718\n",
      "TRAIN: EPOCH 0047 / 0100 | BATCH 0006 / 0012 | LOSS 0.1704\n",
      "TRAIN: EPOCH 0047 / 0100 | BATCH 0007 / 0012 | LOSS 0.1735\n",
      "TRAIN: EPOCH 0047 / 0100 | BATCH 0008 / 0012 | LOSS 0.1770\n",
      "TRAIN: EPOCH 0047 / 0100 | BATCH 0009 / 0012 | LOSS 0.1756\n",
      "TRAIN: EPOCH 0047 / 0100 | BATCH 0010 / 0012 | LOSS 0.1762\n",
      "TRAIN: EPOCH 0047 / 0100 | BATCH 0011 / 0012 | LOSS 0.1749\n",
      "TRAIN: EPOCH 0047 / 0100 | BATCH 0012 / 0012 | LOSS 0.1762\n",
      "VALID: EPOCH 0047 / 0100 | BATCH 0001 / 0002 | LOSS 0.1883\n",
      "VALID: EPOCH 0047 / 0100 | BATCH 0002 / 0002 | LOSS 0.2115\n",
      "TRAIN: EPOCH 0048 / 0100 | BATCH 0001 / 0012 | LOSS 0.1729\n",
      "TRAIN: EPOCH 0048 / 0100 | BATCH 0002 / 0012 | LOSS 0.1627\n",
      "TRAIN: EPOCH 0048 / 0100 | BATCH 0003 / 0012 | LOSS 0.1708\n",
      "TRAIN: EPOCH 0048 / 0100 | BATCH 0004 / 0012 | LOSS 0.1664\n",
      "TRAIN: EPOCH 0048 / 0100 | BATCH 0005 / 0012 | LOSS 0.1684\n",
      "TRAIN: EPOCH 0048 / 0100 | BATCH 0006 / 0012 | LOSS 0.1707\n",
      "TRAIN: EPOCH 0048 / 0100 | BATCH 0007 / 0012 | LOSS 0.1700\n",
      "TRAIN: EPOCH 0048 / 0100 | BATCH 0008 / 0012 | LOSS 0.1691\n",
      "TRAIN: EPOCH 0048 / 0100 | BATCH 0009 / 0012 | LOSS 0.1678\n",
      "TRAIN: EPOCH 0048 / 0100 | BATCH 0010 / 0012 | LOSS 0.1708\n",
      "TRAIN: EPOCH 0048 / 0100 | BATCH 0011 / 0012 | LOSS 0.1710\n",
      "TRAIN: EPOCH 0048 / 0100 | BATCH 0012 / 0012 | LOSS 0.1733\n",
      "VALID: EPOCH 0048 / 0100 | BATCH 0001 / 0002 | LOSS 0.1782\n",
      "VALID: EPOCH 0048 / 0100 | BATCH 0002 / 0002 | LOSS 0.1963\n",
      "TRAIN: EPOCH 0049 / 0100 | BATCH 0001 / 0012 | LOSS 0.1656\n",
      "TRAIN: EPOCH 0049 / 0100 | BATCH 0002 / 0012 | LOSS 0.1677\n",
      "TRAIN: EPOCH 0049 / 0100 | BATCH 0003 / 0012 | LOSS 0.1590\n",
      "TRAIN: EPOCH 0049 / 0100 | BATCH 0004 / 0012 | LOSS 0.1711\n",
      "TRAIN: EPOCH 0049 / 0100 | BATCH 0005 / 0012 | LOSS 0.1674\n",
      "TRAIN: EPOCH 0049 / 0100 | BATCH 0006 / 0012 | LOSS 0.1678\n",
      "TRAIN: EPOCH 0049 / 0100 | BATCH 0007 / 0012 | LOSS 0.1663\n",
      "TRAIN: EPOCH 0049 / 0100 | BATCH 0008 / 0012 | LOSS 0.1688\n",
      "TRAIN: EPOCH 0049 / 0100 | BATCH 0009 / 0012 | LOSS 0.1671\n",
      "TRAIN: EPOCH 0049 / 0100 | BATCH 0010 / 0012 | LOSS 0.1695\n",
      "TRAIN: EPOCH 0049 / 0100 | BATCH 0011 / 0012 | LOSS 0.1723\n",
      "TRAIN: EPOCH 0049 / 0100 | BATCH 0012 / 0012 | LOSS 0.1716\n",
      "VALID: EPOCH 0049 / 0100 | BATCH 0001 / 0002 | LOSS 0.1816\n",
      "VALID: EPOCH 0049 / 0100 | BATCH 0002 / 0002 | LOSS 0.1965\n",
      "TRAIN: EPOCH 0050 / 0100 | BATCH 0001 / 0012 | LOSS 0.2129\n",
      "TRAIN: EPOCH 0050 / 0100 | BATCH 0002 / 0012 | LOSS 0.1839\n",
      "TRAIN: EPOCH 0050 / 0100 | BATCH 0003 / 0012 | LOSS 0.1849\n",
      "TRAIN: EPOCH 0050 / 0100 | BATCH 0004 / 0012 | LOSS 0.1794\n",
      "TRAIN: EPOCH 0050 / 0100 | BATCH 0005 / 0012 | LOSS 0.1754\n",
      "TRAIN: EPOCH 0050 / 0100 | BATCH 0006 / 0012 | LOSS 0.1758\n",
      "TRAIN: EPOCH 0050 / 0100 | BATCH 0007 / 0012 | LOSS 0.1715\n",
      "TRAIN: EPOCH 0050 / 0100 | BATCH 0008 / 0012 | LOSS 0.1739\n",
      "TRAIN: EPOCH 0050 / 0100 | BATCH 0009 / 0012 | LOSS 0.1740\n",
      "TRAIN: EPOCH 0050 / 0100 | BATCH 0010 / 0012 | LOSS 0.1725\n",
      "TRAIN: EPOCH 0050 / 0100 | BATCH 0011 / 0012 | LOSS 0.1712\n",
      "TRAIN: EPOCH 0050 / 0100 | BATCH 0012 / 0012 | LOSS 0.1701\n",
      "VALID: EPOCH 0050 / 0100 | BATCH 0001 / 0002 | LOSS 0.1821\n",
      "VALID: EPOCH 0050 / 0100 | BATCH 0002 / 0002 | LOSS 0.2005\n",
      "TRAIN: EPOCH 0051 / 0100 | BATCH 0001 / 0012 | LOSS 0.1637\n",
      "TRAIN: EPOCH 0051 / 0100 | BATCH 0002 / 0012 | LOSS 0.1664\n",
      "TRAIN: EPOCH 0051 / 0100 | BATCH 0003 / 0012 | LOSS 0.1622\n",
      "TRAIN: EPOCH 0051 / 0100 | BATCH 0004 / 0012 | LOSS 0.1631\n",
      "TRAIN: EPOCH 0051 / 0100 | BATCH 0005 / 0012 | LOSS 0.1601\n",
      "TRAIN: EPOCH 0051 / 0100 | BATCH 0006 / 0012 | LOSS 0.1648\n",
      "TRAIN: EPOCH 0051 / 0100 | BATCH 0007 / 0012 | LOSS 0.1664\n",
      "TRAIN: EPOCH 0051 / 0100 | BATCH 0008 / 0012 | LOSS 0.1645\n",
      "TRAIN: EPOCH 0051 / 0100 | BATCH 0009 / 0012 | LOSS 0.1659\n",
      "TRAIN: EPOCH 0051 / 0100 | BATCH 0010 / 0012 | LOSS 0.1664\n",
      "TRAIN: EPOCH 0051 / 0100 | BATCH 0011 / 0012 | LOSS 0.1659\n",
      "TRAIN: EPOCH 0051 / 0100 | BATCH 0012 / 0012 | LOSS 0.1658\n",
      "VALID: EPOCH 0051 / 0100 | BATCH 0001 / 0002 | LOSS 0.1841\n",
      "VALID: EPOCH 0051 / 0100 | BATCH 0002 / 0002 | LOSS 0.2075\n",
      "TRAIN: EPOCH 0052 / 0100 | BATCH 0001 / 0012 | LOSS 0.1538\n",
      "TRAIN: EPOCH 0052 / 0100 | BATCH 0002 / 0012 | LOSS 0.1470\n",
      "TRAIN: EPOCH 0052 / 0100 | BATCH 0003 / 0012 | LOSS 0.1617\n",
      "TRAIN: EPOCH 0052 / 0100 | BATCH 0004 / 0012 | LOSS 0.1646\n",
      "TRAIN: EPOCH 0052 / 0100 | BATCH 0005 / 0012 | LOSS 0.1662\n",
      "TRAIN: EPOCH 0052 / 0100 | BATCH 0006 / 0012 | LOSS 0.1678\n",
      "TRAIN: EPOCH 0052 / 0100 | BATCH 0007 / 0012 | LOSS 0.1676\n",
      "TRAIN: EPOCH 0052 / 0100 | BATCH 0008 / 0012 | LOSS 0.1649\n",
      "TRAIN: EPOCH 0052 / 0100 | BATCH 0009 / 0012 | LOSS 0.1657\n",
      "TRAIN: EPOCH 0052 / 0100 | BATCH 0010 / 0012 | LOSS 0.1683\n",
      "TRAIN: EPOCH 0052 / 0100 | BATCH 0011 / 0012 | LOSS 0.1684\n",
      "TRAIN: EPOCH 0052 / 0100 | BATCH 0012 / 0012 | LOSS 0.1675\n",
      "VALID: EPOCH 0052 / 0100 | BATCH 0001 / 0002 | LOSS 0.2069\n",
      "VALID: EPOCH 0052 / 0100 | BATCH 0002 / 0002 | LOSS 0.2318\n",
      "TRAIN: EPOCH 0053 / 0100 | BATCH 0001 / 0012 | LOSS 0.1437\n",
      "TRAIN: EPOCH 0053 / 0100 | BATCH 0002 / 0012 | LOSS 0.1574\n",
      "TRAIN: EPOCH 0053 / 0100 | BATCH 0003 / 0012 | LOSS 0.1643\n",
      "TRAIN: EPOCH 0053 / 0100 | BATCH 0004 / 0012 | LOSS 0.1618\n",
      "TRAIN: EPOCH 0053 / 0100 | BATCH 0005 / 0012 | LOSS 0.1594\n",
      "TRAIN: EPOCH 0053 / 0100 | BATCH 0006 / 0012 | LOSS 0.1635\n",
      "TRAIN: EPOCH 0053 / 0100 | BATCH 0007 / 0012 | LOSS 0.1622\n",
      "TRAIN: EPOCH 0053 / 0100 | BATCH 0008 / 0012 | LOSS 0.1627\n",
      "TRAIN: EPOCH 0053 / 0100 | BATCH 0009 / 0012 | LOSS 0.1659\n",
      "TRAIN: EPOCH 0053 / 0100 | BATCH 0010 / 0012 | LOSS 0.1657\n",
      "TRAIN: EPOCH 0053 / 0100 | BATCH 0011 / 0012 | LOSS 0.1674\n",
      "TRAIN: EPOCH 0053 / 0100 | BATCH 0012 / 0012 | LOSS 0.1680\n",
      "VALID: EPOCH 0053 / 0100 | BATCH 0001 / 0002 | LOSS 0.1804\n",
      "VALID: EPOCH 0053 / 0100 | BATCH 0002 / 0002 | LOSS 0.2084\n",
      "TRAIN: EPOCH 0054 / 0100 | BATCH 0001 / 0012 | LOSS 0.1627\n",
      "TRAIN: EPOCH 0054 / 0100 | BATCH 0002 / 0012 | LOSS 0.1704\n",
      "TRAIN: EPOCH 0054 / 0100 | BATCH 0003 / 0012 | LOSS 0.1659\n",
      "TRAIN: EPOCH 0054 / 0100 | BATCH 0004 / 0012 | LOSS 0.1641\n",
      "TRAIN: EPOCH 0054 / 0100 | BATCH 0005 / 0012 | LOSS 0.1632\n",
      "TRAIN: EPOCH 0054 / 0100 | BATCH 0006 / 0012 | LOSS 0.1610\n",
      "TRAIN: EPOCH 0054 / 0100 | BATCH 0007 / 0012 | LOSS 0.1607\n",
      "TRAIN: EPOCH 0054 / 0100 | BATCH 0008 / 0012 | LOSS 0.1617\n",
      "TRAIN: EPOCH 0054 / 0100 | BATCH 0009 / 0012 | LOSS 0.1590\n",
      "TRAIN: EPOCH 0054 / 0100 | BATCH 0010 / 0012 | LOSS 0.1630\n",
      "TRAIN: EPOCH 0054 / 0100 | BATCH 0011 / 0012 | LOSS 0.1634\n",
      "TRAIN: EPOCH 0054 / 0100 | BATCH 0012 / 0012 | LOSS 0.1643\n",
      "VALID: EPOCH 0054 / 0100 | BATCH 0001 / 0002 | LOSS 0.1867\n",
      "VALID: EPOCH 0054 / 0100 | BATCH 0002 / 0002 | LOSS 0.2033\n",
      "TRAIN: EPOCH 0055 / 0100 | BATCH 0001 / 0012 | LOSS 0.1636\n",
      "TRAIN: EPOCH 0055 / 0100 | BATCH 0002 / 0012 | LOSS 0.1620\n",
      "TRAIN: EPOCH 0055 / 0100 | BATCH 0003 / 0012 | LOSS 0.1597\n",
      "TRAIN: EPOCH 0055 / 0100 | BATCH 0004 / 0012 | LOSS 0.1608\n",
      "TRAIN: EPOCH 0055 / 0100 | BATCH 0005 / 0012 | LOSS 0.1603\n",
      "TRAIN: EPOCH 0055 / 0100 | BATCH 0006 / 0012 | LOSS 0.1596\n",
      "TRAIN: EPOCH 0055 / 0100 | BATCH 0007 / 0012 | LOSS 0.1620\n",
      "TRAIN: EPOCH 0055 / 0100 | BATCH 0008 / 0012 | LOSS 0.1643\n",
      "TRAIN: EPOCH 0055 / 0100 | BATCH 0009 / 0012 | LOSS 0.1632\n",
      "TRAIN: EPOCH 0055 / 0100 | BATCH 0010 / 0012 | LOSS 0.1633\n",
      "TRAIN: EPOCH 0055 / 0100 | BATCH 0011 / 0012 | LOSS 0.1662\n",
      "TRAIN: EPOCH 0055 / 0100 | BATCH 0012 / 0012 | LOSS 0.1647\n",
      "VALID: EPOCH 0055 / 0100 | BATCH 0001 / 0002 | LOSS 0.1873\n",
      "VALID: EPOCH 0055 / 0100 | BATCH 0002 / 0002 | LOSS 0.2200\n",
      "TRAIN: EPOCH 0056 / 0100 | BATCH 0001 / 0012 | LOSS 0.1581\n",
      "TRAIN: EPOCH 0056 / 0100 | BATCH 0002 / 0012 | LOSS 0.1666\n",
      "TRAIN: EPOCH 0056 / 0100 | BATCH 0003 / 0012 | LOSS 0.1615\n",
      "TRAIN: EPOCH 0056 / 0100 | BATCH 0004 / 0012 | LOSS 0.1568\n",
      "TRAIN: EPOCH 0056 / 0100 | BATCH 0005 / 0012 | LOSS 0.1610\n",
      "TRAIN: EPOCH 0056 / 0100 | BATCH 0006 / 0012 | LOSS 0.1569\n",
      "TRAIN: EPOCH 0056 / 0100 | BATCH 0007 / 0012 | LOSS 0.1615\n",
      "TRAIN: EPOCH 0056 / 0100 | BATCH 0008 / 0012 | LOSS 0.1617\n",
      "TRAIN: EPOCH 0056 / 0100 | BATCH 0009 / 0012 | LOSS 0.1605\n",
      "TRAIN: EPOCH 0056 / 0100 | BATCH 0010 / 0012 | LOSS 0.1630\n",
      "TRAIN: EPOCH 0056 / 0100 | BATCH 0011 / 0012 | LOSS 0.1636\n",
      "TRAIN: EPOCH 0056 / 0100 | BATCH 0012 / 0012 | LOSS 0.1630\n",
      "VALID: EPOCH 0056 / 0100 | BATCH 0001 / 0002 | LOSS 0.1980\n",
      "VALID: EPOCH 0056 / 0100 | BATCH 0002 / 0002 | LOSS 0.2354\n",
      "TRAIN: EPOCH 0057 / 0100 | BATCH 0001 / 0012 | LOSS 0.1830\n",
      "TRAIN: EPOCH 0057 / 0100 | BATCH 0002 / 0012 | LOSS 0.1692\n",
      "TRAIN: EPOCH 0057 / 0100 | BATCH 0003 / 0012 | LOSS 0.1738\n",
      "TRAIN: EPOCH 0057 / 0100 | BATCH 0004 / 0012 | LOSS 0.1706\n",
      "TRAIN: EPOCH 0057 / 0100 | BATCH 0005 / 0012 | LOSS 0.1762\n",
      "TRAIN: EPOCH 0057 / 0100 | BATCH 0006 / 0012 | LOSS 0.1730\n",
      "TRAIN: EPOCH 0057 / 0100 | BATCH 0007 / 0012 | LOSS 0.1710\n",
      "TRAIN: EPOCH 0057 / 0100 | BATCH 0008 / 0012 | LOSS 0.1756\n",
      "TRAIN: EPOCH 0057 / 0100 | BATCH 0009 / 0012 | LOSS 0.1741\n",
      "TRAIN: EPOCH 0057 / 0100 | BATCH 0010 / 0012 | LOSS 0.1737\n",
      "TRAIN: EPOCH 0057 / 0100 | BATCH 0011 / 0012 | LOSS 0.1724\n",
      "TRAIN: EPOCH 0057 / 0100 | BATCH 0012 / 0012 | LOSS 0.1714\n",
      "VALID: EPOCH 0057 / 0100 | BATCH 0001 / 0002 | LOSS 0.1957\n",
      "VALID: EPOCH 0057 / 0100 | BATCH 0002 / 0002 | LOSS 0.2131\n",
      "TRAIN: EPOCH 0058 / 0100 | BATCH 0001 / 0012 | LOSS 0.1636\n",
      "TRAIN: EPOCH 0058 / 0100 | BATCH 0002 / 0012 | LOSS 0.1820\n",
      "TRAIN: EPOCH 0058 / 0100 | BATCH 0003 / 0012 | LOSS 0.1749\n",
      "TRAIN: EPOCH 0058 / 0100 | BATCH 0004 / 0012 | LOSS 0.1756\n",
      "TRAIN: EPOCH 0058 / 0100 | BATCH 0005 / 0012 | LOSS 0.1725\n",
      "TRAIN: EPOCH 0058 / 0100 | BATCH 0006 / 0012 | LOSS 0.1717\n",
      "TRAIN: EPOCH 0058 / 0100 | BATCH 0007 / 0012 | LOSS 0.1688\n",
      "TRAIN: EPOCH 0058 / 0100 | BATCH 0008 / 0012 | LOSS 0.1665\n",
      "TRAIN: EPOCH 0058 / 0100 | BATCH 0009 / 0012 | LOSS 0.1660\n",
      "TRAIN: EPOCH 0058 / 0100 | BATCH 0010 / 0012 | LOSS 0.1643\n",
      "TRAIN: EPOCH 0058 / 0100 | BATCH 0011 / 0012 | LOSS 0.1653\n",
      "TRAIN: EPOCH 0058 / 0100 | BATCH 0012 / 0012 | LOSS 0.1647\n",
      "VALID: EPOCH 0058 / 0100 | BATCH 0001 / 0002 | LOSS 0.1807\n",
      "VALID: EPOCH 0058 / 0100 | BATCH 0002 / 0002 | LOSS 0.2075\n",
      "TRAIN: EPOCH 0059 / 0100 | BATCH 0001 / 0012 | LOSS 0.1493\n",
      "TRAIN: EPOCH 0059 / 0100 | BATCH 0002 / 0012 | LOSS 0.1560\n",
      "TRAIN: EPOCH 0059 / 0100 | BATCH 0003 / 0012 | LOSS 0.1606\n",
      "TRAIN: EPOCH 0059 / 0100 | BATCH 0004 / 0012 | LOSS 0.1588\n",
      "TRAIN: EPOCH 0059 / 0100 | BATCH 0005 / 0012 | LOSS 0.1577\n",
      "TRAIN: EPOCH 0059 / 0100 | BATCH 0006 / 0012 | LOSS 0.1561\n",
      "TRAIN: EPOCH 0059 / 0100 | BATCH 0007 / 0012 | LOSS 0.1592\n",
      "TRAIN: EPOCH 0059 / 0100 | BATCH 0008 / 0012 | LOSS 0.1603\n",
      "TRAIN: EPOCH 0059 / 0100 | BATCH 0009 / 0012 | LOSS 0.1591\n",
      "TRAIN: EPOCH 0059 / 0100 | BATCH 0010 / 0012 | LOSS 0.1591\n",
      "TRAIN: EPOCH 0059 / 0100 | BATCH 0011 / 0012 | LOSS 0.1631\n",
      "TRAIN: EPOCH 0059 / 0100 | BATCH 0012 / 0012 | LOSS 0.1618\n",
      "VALID: EPOCH 0059 / 0100 | BATCH 0001 / 0002 | LOSS 0.1827\n",
      "VALID: EPOCH 0059 / 0100 | BATCH 0002 / 0002 | LOSS 0.2109\n",
      "TRAIN: EPOCH 0060 / 0100 | BATCH 0001 / 0012 | LOSS 0.1718\n",
      "TRAIN: EPOCH 0060 / 0100 | BATCH 0002 / 0012 | LOSS 0.1675\n",
      "TRAIN: EPOCH 0060 / 0100 | BATCH 0003 / 0012 | LOSS 0.1642\n",
      "TRAIN: EPOCH 0060 / 0100 | BATCH 0004 / 0012 | LOSS 0.1617\n",
      "TRAIN: EPOCH 0060 / 0100 | BATCH 0005 / 0012 | LOSS 0.1703\n",
      "TRAIN: EPOCH 0060 / 0100 | BATCH 0006 / 0012 | LOSS 0.1703\n",
      "TRAIN: EPOCH 0060 / 0100 | BATCH 0007 / 0012 | LOSS 0.1682\n",
      "TRAIN: EPOCH 0060 / 0100 | BATCH 0008 / 0012 | LOSS 0.1644\n",
      "TRAIN: EPOCH 0060 / 0100 | BATCH 0009 / 0012 | LOSS 0.1621\n",
      "TRAIN: EPOCH 0060 / 0100 | BATCH 0010 / 0012 | LOSS 0.1611\n",
      "TRAIN: EPOCH 0060 / 0100 | BATCH 0011 / 0012 | LOSS 0.1601\n",
      "TRAIN: EPOCH 0060 / 0100 | BATCH 0012 / 0012 | LOSS 0.1580\n",
      "VALID: EPOCH 0060 / 0100 | BATCH 0001 / 0002 | LOSS 0.2026\n",
      "VALID: EPOCH 0060 / 0100 | BATCH 0002 / 0002 | LOSS 0.2139\n",
      "TRAIN: EPOCH 0061 / 0100 | BATCH 0001 / 0012 | LOSS 0.1690\n",
      "TRAIN: EPOCH 0061 / 0100 | BATCH 0002 / 0012 | LOSS 0.1686\n",
      "TRAIN: EPOCH 0061 / 0100 | BATCH 0003 / 0012 | LOSS 0.1646\n",
      "TRAIN: EPOCH 0061 / 0100 | BATCH 0004 / 0012 | LOSS 0.1630\n",
      "TRAIN: EPOCH 0061 / 0100 | BATCH 0005 / 0012 | LOSS 0.1618\n",
      "TRAIN: EPOCH 0061 / 0100 | BATCH 0006 / 0012 | LOSS 0.1582\n",
      "TRAIN: EPOCH 0061 / 0100 | BATCH 0007 / 0012 | LOSS 0.1663\n",
      "TRAIN: EPOCH 0061 / 0100 | BATCH 0008 / 0012 | LOSS 0.1672\n",
      "TRAIN: EPOCH 0061 / 0100 | BATCH 0009 / 0012 | LOSS 0.1670\n",
      "TRAIN: EPOCH 0061 / 0100 | BATCH 0010 / 0012 | LOSS 0.1671\n",
      "TRAIN: EPOCH 0061 / 0100 | BATCH 0011 / 0012 | LOSS 0.1671\n",
      "TRAIN: EPOCH 0061 / 0100 | BATCH 0012 / 0012 | LOSS 0.1661\n",
      "VALID: EPOCH 0061 / 0100 | BATCH 0001 / 0002 | LOSS 0.1859\n",
      "VALID: EPOCH 0061 / 0100 | BATCH 0002 / 0002 | LOSS 0.2206\n",
      "TRAIN: EPOCH 0062 / 0100 | BATCH 0001 / 0012 | LOSS 0.1686\n",
      "TRAIN: EPOCH 0062 / 0100 | BATCH 0002 / 0012 | LOSS 0.1674\n",
      "TRAIN: EPOCH 0062 / 0100 | BATCH 0003 / 0012 | LOSS 0.1641\n",
      "TRAIN: EPOCH 0062 / 0100 | BATCH 0004 / 0012 | LOSS 0.1634\n",
      "TRAIN: EPOCH 0062 / 0100 | BATCH 0005 / 0012 | LOSS 0.1631\n",
      "TRAIN: EPOCH 0062 / 0100 | BATCH 0006 / 0012 | LOSS 0.1650\n",
      "TRAIN: EPOCH 0062 / 0100 | BATCH 0007 / 0012 | LOSS 0.1683\n",
      "TRAIN: EPOCH 0062 / 0100 | BATCH 0008 / 0012 | LOSS 0.1668\n",
      "TRAIN: EPOCH 0062 / 0100 | BATCH 0009 / 0012 | LOSS 0.1675\n",
      "TRAIN: EPOCH 0062 / 0100 | BATCH 0010 / 0012 | LOSS 0.1660\n",
      "TRAIN: EPOCH 0062 / 0100 | BATCH 0011 / 0012 | LOSS 0.1677\n",
      "TRAIN: EPOCH 0062 / 0100 | BATCH 0012 / 0012 | LOSS 0.1665\n",
      "VALID: EPOCH 0062 / 0100 | BATCH 0001 / 0002 | LOSS 0.1996\n",
      "VALID: EPOCH 0062 / 0100 | BATCH 0002 / 0002 | LOSS 0.2168\n",
      "TRAIN: EPOCH 0063 / 0100 | BATCH 0001 / 0012 | LOSS 0.1652\n",
      "TRAIN: EPOCH 0063 / 0100 | BATCH 0002 / 0012 | LOSS 0.1705\n",
      "TRAIN: EPOCH 0063 / 0100 | BATCH 0003 / 0012 | LOSS 0.1715\n",
      "TRAIN: EPOCH 0063 / 0100 | BATCH 0004 / 0012 | LOSS 0.1700\n",
      "TRAIN: EPOCH 0063 / 0100 | BATCH 0005 / 0012 | LOSS 0.1667\n",
      "TRAIN: EPOCH 0063 / 0100 | BATCH 0006 / 0012 | LOSS 0.1662\n",
      "TRAIN: EPOCH 0063 / 0100 | BATCH 0007 / 0012 | LOSS 0.1651\n",
      "TRAIN: EPOCH 0063 / 0100 | BATCH 0008 / 0012 | LOSS 0.1621\n",
      "TRAIN: EPOCH 0063 / 0100 | BATCH 0009 / 0012 | LOSS 0.1610\n",
      "TRAIN: EPOCH 0063 / 0100 | BATCH 0010 / 0012 | LOSS 0.1606\n",
      "TRAIN: EPOCH 0063 / 0100 | BATCH 0011 / 0012 | LOSS 0.1615\n",
      "TRAIN: EPOCH 0063 / 0100 | BATCH 0012 / 0012 | LOSS 0.1608\n",
      "VALID: EPOCH 0063 / 0100 | BATCH 0001 / 0002 | LOSS 0.1875\n",
      "VALID: EPOCH 0063 / 0100 | BATCH 0002 / 0002 | LOSS 0.2179\n",
      "TRAIN: EPOCH 0064 / 0100 | BATCH 0001 / 0012 | LOSS 0.1604\n",
      "TRAIN: EPOCH 0064 / 0100 | BATCH 0002 / 0012 | LOSS 0.1641\n",
      "TRAIN: EPOCH 0064 / 0100 | BATCH 0003 / 0012 | LOSS 0.1584\n",
      "TRAIN: EPOCH 0064 / 0100 | BATCH 0004 / 0012 | LOSS 0.1570\n",
      "TRAIN: EPOCH 0064 / 0100 | BATCH 0005 / 0012 | LOSS 0.1581\n",
      "TRAIN: EPOCH 0064 / 0100 | BATCH 0006 / 0012 | LOSS 0.1587\n",
      "TRAIN: EPOCH 0064 / 0100 | BATCH 0007 / 0012 | LOSS 0.1573\n",
      "TRAIN: EPOCH 0064 / 0100 | BATCH 0008 / 0012 | LOSS 0.1581\n",
      "TRAIN: EPOCH 0064 / 0100 | BATCH 0009 / 0012 | LOSS 0.1571\n",
      "TRAIN: EPOCH 0064 / 0100 | BATCH 0010 / 0012 | LOSS 0.1573\n",
      "TRAIN: EPOCH 0064 / 0100 | BATCH 0011 / 0012 | LOSS 0.1615\n",
      "TRAIN: EPOCH 0064 / 0100 | BATCH 0012 / 0012 | LOSS 0.1604\n",
      "VALID: EPOCH 0064 / 0100 | BATCH 0001 / 0002 | LOSS 0.1890\n",
      "VALID: EPOCH 0064 / 0100 | BATCH 0002 / 0002 | LOSS 0.2204\n",
      "TRAIN: EPOCH 0065 / 0100 | BATCH 0001 / 0012 | LOSS 0.1587\n",
      "TRAIN: EPOCH 0065 / 0100 | BATCH 0002 / 0012 | LOSS 0.1668\n",
      "TRAIN: EPOCH 0065 / 0100 | BATCH 0003 / 0012 | LOSS 0.1600\n",
      "TRAIN: EPOCH 0065 / 0100 | BATCH 0004 / 0012 | LOSS 0.1595\n",
      "TRAIN: EPOCH 0065 / 0100 | BATCH 0005 / 0012 | LOSS 0.1579\n",
      "TRAIN: EPOCH 0065 / 0100 | BATCH 0006 / 0012 | LOSS 0.1579\n",
      "TRAIN: EPOCH 0065 / 0100 | BATCH 0007 / 0012 | LOSS 0.1586\n",
      "TRAIN: EPOCH 0065 / 0100 | BATCH 0008 / 0012 | LOSS 0.1574\n",
      "TRAIN: EPOCH 0065 / 0100 | BATCH 0009 / 0012 | LOSS 0.1567\n",
      "TRAIN: EPOCH 0065 / 0100 | BATCH 0010 / 0012 | LOSS 0.1553\n",
      "TRAIN: EPOCH 0065 / 0100 | BATCH 0011 / 0012 | LOSS 0.1561\n",
      "TRAIN: EPOCH 0065 / 0100 | BATCH 0012 / 0012 | LOSS 0.1588\n",
      "VALID: EPOCH 0065 / 0100 | BATCH 0001 / 0002 | LOSS 0.1733\n",
      "VALID: EPOCH 0065 / 0100 | BATCH 0002 / 0002 | LOSS 0.2003\n",
      "TRAIN: EPOCH 0066 / 0100 | BATCH 0001 / 0012 | LOSS 0.1449\n",
      "TRAIN: EPOCH 0066 / 0100 | BATCH 0002 / 0012 | LOSS 0.1466\n",
      "TRAIN: EPOCH 0066 / 0100 | BATCH 0003 / 0012 | LOSS 0.1582\n",
      "TRAIN: EPOCH 0066 / 0100 | BATCH 0004 / 0012 | LOSS 0.1587\n",
      "TRAIN: EPOCH 0066 / 0100 | BATCH 0005 / 0012 | LOSS 0.1591\n",
      "TRAIN: EPOCH 0066 / 0100 | BATCH 0006 / 0012 | LOSS 0.1591\n",
      "TRAIN: EPOCH 0066 / 0100 | BATCH 0007 / 0012 | LOSS 0.1595\n",
      "TRAIN: EPOCH 0066 / 0100 | BATCH 0008 / 0012 | LOSS 0.1608\n",
      "TRAIN: EPOCH 0066 / 0100 | BATCH 0009 / 0012 | LOSS 0.1593\n",
      "TRAIN: EPOCH 0066 / 0100 | BATCH 0010 / 0012 | LOSS 0.1593\n",
      "TRAIN: EPOCH 0066 / 0100 | BATCH 0011 / 0012 | LOSS 0.1594\n",
      "TRAIN: EPOCH 0066 / 0100 | BATCH 0012 / 0012 | LOSS 0.1606\n",
      "VALID: EPOCH 0066 / 0100 | BATCH 0001 / 0002 | LOSS 0.1862\n",
      "VALID: EPOCH 0066 / 0100 | BATCH 0002 / 0002 | LOSS 0.2092\n",
      "TRAIN: EPOCH 0067 / 0100 | BATCH 0001 / 0012 | LOSS 0.1431\n",
      "TRAIN: EPOCH 0067 / 0100 | BATCH 0002 / 0012 | LOSS 0.1453\n",
      "TRAIN: EPOCH 0067 / 0100 | BATCH 0003 / 0012 | LOSS 0.1461\n",
      "TRAIN: EPOCH 0067 / 0100 | BATCH 0004 / 0012 | LOSS 0.1560\n",
      "TRAIN: EPOCH 0067 / 0100 | BATCH 0005 / 0012 | LOSS 0.1621\n",
      "TRAIN: EPOCH 0067 / 0100 | BATCH 0006 / 0012 | LOSS 0.1628\n",
      "TRAIN: EPOCH 0067 / 0100 | BATCH 0007 / 0012 | LOSS 0.1620\n",
      "TRAIN: EPOCH 0067 / 0100 | BATCH 0008 / 0012 | LOSS 0.1609\n",
      "TRAIN: EPOCH 0067 / 0100 | BATCH 0009 / 0012 | LOSS 0.1613\n",
      "TRAIN: EPOCH 0067 / 0100 | BATCH 0010 / 0012 | LOSS 0.1613\n",
      "TRAIN: EPOCH 0067 / 0100 | BATCH 0011 / 0012 | LOSS 0.1607\n",
      "TRAIN: EPOCH 0067 / 0100 | BATCH 0012 / 0012 | LOSS 0.1609\n",
      "VALID: EPOCH 0067 / 0100 | BATCH 0001 / 0002 | LOSS 0.1837\n",
      "VALID: EPOCH 0067 / 0100 | BATCH 0002 / 0002 | LOSS 0.2068\n",
      "TRAIN: EPOCH 0068 / 0100 | BATCH 0001 / 0012 | LOSS 0.1482\n",
      "TRAIN: EPOCH 0068 / 0100 | BATCH 0002 / 0012 | LOSS 0.1517\n",
      "TRAIN: EPOCH 0068 / 0100 | BATCH 0003 / 0012 | LOSS 0.1528\n",
      "TRAIN: EPOCH 0068 / 0100 | BATCH 0004 / 0012 | LOSS 0.1528\n",
      "TRAIN: EPOCH 0068 / 0100 | BATCH 0005 / 0012 | LOSS 0.1556\n",
      "TRAIN: EPOCH 0068 / 0100 | BATCH 0006 / 0012 | LOSS 0.1541\n",
      "TRAIN: EPOCH 0068 / 0100 | BATCH 0007 / 0012 | LOSS 0.1535\n",
      "TRAIN: EPOCH 0068 / 0100 | BATCH 0008 / 0012 | LOSS 0.1539\n",
      "TRAIN: EPOCH 0068 / 0100 | BATCH 0009 / 0012 | LOSS 0.1560\n",
      "TRAIN: EPOCH 0068 / 0100 | BATCH 0010 / 0012 | LOSS 0.1563\n",
      "TRAIN: EPOCH 0068 / 0100 | BATCH 0011 / 0012 | LOSS 0.1573\n",
      "TRAIN: EPOCH 0068 / 0100 | BATCH 0012 / 0012 | LOSS 0.1579\n",
      "VALID: EPOCH 0068 / 0100 | BATCH 0001 / 0002 | LOSS 0.1834\n",
      "VALID: EPOCH 0068 / 0100 | BATCH 0002 / 0002 | LOSS 0.2134\n",
      "TRAIN: EPOCH 0069 / 0100 | BATCH 0001 / 0012 | LOSS 0.1710\n",
      "TRAIN: EPOCH 0069 / 0100 | BATCH 0002 / 0012 | LOSS 0.1676\n",
      "TRAIN: EPOCH 0069 / 0100 | BATCH 0003 / 0012 | LOSS 0.1633\n",
      "TRAIN: EPOCH 0069 / 0100 | BATCH 0004 / 0012 | LOSS 0.1601\n",
      "TRAIN: EPOCH 0069 / 0100 | BATCH 0005 / 0012 | LOSS 0.1579\n",
      "TRAIN: EPOCH 0069 / 0100 | BATCH 0006 / 0012 | LOSS 0.1593\n",
      "TRAIN: EPOCH 0069 / 0100 | BATCH 0007 / 0012 | LOSS 0.1584\n",
      "TRAIN: EPOCH 0069 / 0100 | BATCH 0008 / 0012 | LOSS 0.1578\n",
      "TRAIN: EPOCH 0069 / 0100 | BATCH 0009 / 0012 | LOSS 0.1574\n",
      "TRAIN: EPOCH 0069 / 0100 | BATCH 0010 / 0012 | LOSS 0.1582\n",
      "TRAIN: EPOCH 0069 / 0100 | BATCH 0011 / 0012 | LOSS 0.1595\n",
      "TRAIN: EPOCH 0069 / 0100 | BATCH 0012 / 0012 | LOSS 0.1613\n",
      "VALID: EPOCH 0069 / 0100 | BATCH 0001 / 0002 | LOSS 0.1929\n",
      "VALID: EPOCH 0069 / 0100 | BATCH 0002 / 0002 | LOSS 0.2225\n",
      "TRAIN: EPOCH 0070 / 0100 | BATCH 0001 / 0012 | LOSS 0.1543\n",
      "TRAIN: EPOCH 0070 / 0100 | BATCH 0002 / 0012 | LOSS 0.1609\n",
      "TRAIN: EPOCH 0070 / 0100 | BATCH 0003 / 0012 | LOSS 0.1624\n",
      "TRAIN: EPOCH 0070 / 0100 | BATCH 0004 / 0012 | LOSS 0.1613\n",
      "TRAIN: EPOCH 0070 / 0100 | BATCH 0005 / 0012 | LOSS 0.1643\n",
      "TRAIN: EPOCH 0070 / 0100 | BATCH 0006 / 0012 | LOSS 0.1654\n",
      "TRAIN: EPOCH 0070 / 0100 | BATCH 0007 / 0012 | LOSS 0.1635\n",
      "TRAIN: EPOCH 0070 / 0100 | BATCH 0008 / 0012 | LOSS 0.1606\n",
      "TRAIN: EPOCH 0070 / 0100 | BATCH 0009 / 0012 | LOSS 0.1594\n",
      "TRAIN: EPOCH 0070 / 0100 | BATCH 0010 / 0012 | LOSS 0.1599\n",
      "TRAIN: EPOCH 0070 / 0100 | BATCH 0011 / 0012 | LOSS 0.1601\n",
      "TRAIN: EPOCH 0070 / 0100 | BATCH 0012 / 0012 | LOSS 0.1588\n",
      "VALID: EPOCH 0070 / 0100 | BATCH 0001 / 0002 | LOSS 0.1849\n",
      "VALID: EPOCH 0070 / 0100 | BATCH 0002 / 0002 | LOSS 0.2084\n",
      "TRAIN: EPOCH 0071 / 0100 | BATCH 0001 / 0012 | LOSS 0.1581\n",
      "TRAIN: EPOCH 0071 / 0100 | BATCH 0002 / 0012 | LOSS 0.1567\n",
      "TRAIN: EPOCH 0071 / 0100 | BATCH 0003 / 0012 | LOSS 0.1573\n",
      "TRAIN: EPOCH 0071 / 0100 | BATCH 0004 / 0012 | LOSS 0.1589\n",
      "TRAIN: EPOCH 0071 / 0100 | BATCH 0005 / 0012 | LOSS 0.1574\n",
      "TRAIN: EPOCH 0071 / 0100 | BATCH 0006 / 0012 | LOSS 0.1586\n",
      "TRAIN: EPOCH 0071 / 0100 | BATCH 0007 / 0012 | LOSS 0.1572\n",
      "TRAIN: EPOCH 0071 / 0100 | BATCH 0008 / 0012 | LOSS 0.1573\n",
      "TRAIN: EPOCH 0071 / 0100 | BATCH 0009 / 0012 | LOSS 0.1560\n",
      "TRAIN: EPOCH 0071 / 0100 | BATCH 0010 / 0012 | LOSS 0.1548\n",
      "TRAIN: EPOCH 0071 / 0100 | BATCH 0011 / 0012 | LOSS 0.1556\n",
      "TRAIN: EPOCH 0071 / 0100 | BATCH 0012 / 0012 | LOSS 0.1558\n",
      "VALID: EPOCH 0071 / 0100 | BATCH 0001 / 0002 | LOSS 0.1820\n",
      "VALID: EPOCH 0071 / 0100 | BATCH 0002 / 0002 | LOSS 0.2137\n",
      "TRAIN: EPOCH 0072 / 0100 | BATCH 0001 / 0012 | LOSS 0.1398\n",
      "TRAIN: EPOCH 0072 / 0100 | BATCH 0002 / 0012 | LOSS 0.1417\n",
      "TRAIN: EPOCH 0072 / 0100 | BATCH 0003 / 0012 | LOSS 0.1432\n",
      "TRAIN: EPOCH 0072 / 0100 | BATCH 0004 / 0012 | LOSS 0.1473\n",
      "TRAIN: EPOCH 0072 / 0100 | BATCH 0005 / 0012 | LOSS 0.1486\n",
      "TRAIN: EPOCH 0072 / 0100 | BATCH 0006 / 0012 | LOSS 0.1495\n",
      "TRAIN: EPOCH 0072 / 0100 | BATCH 0007 / 0012 | LOSS 0.1484\n",
      "TRAIN: EPOCH 0072 / 0100 | BATCH 0008 / 0012 | LOSS 0.1508\n",
      "TRAIN: EPOCH 0072 / 0100 | BATCH 0009 / 0012 | LOSS 0.1545\n",
      "TRAIN: EPOCH 0072 / 0100 | BATCH 0010 / 0012 | LOSS 0.1544\n",
      "TRAIN: EPOCH 0072 / 0100 | BATCH 0011 / 0012 | LOSS 0.1548\n",
      "TRAIN: EPOCH 0072 / 0100 | BATCH 0012 / 0012 | LOSS 0.1558\n",
      "VALID: EPOCH 0072 / 0100 | BATCH 0001 / 0002 | LOSS 0.1887\n",
      "VALID: EPOCH 0072 / 0100 | BATCH 0002 / 0002 | LOSS 0.2178\n",
      "TRAIN: EPOCH 0073 / 0100 | BATCH 0001 / 0012 | LOSS 0.1570\n",
      "TRAIN: EPOCH 0073 / 0100 | BATCH 0002 / 0012 | LOSS 0.1607\n",
      "TRAIN: EPOCH 0073 / 0100 | BATCH 0003 / 0012 | LOSS 0.1610\n",
      "TRAIN: EPOCH 0073 / 0100 | BATCH 0004 / 0012 | LOSS 0.1584\n",
      "TRAIN: EPOCH 0073 / 0100 | BATCH 0005 / 0012 | LOSS 0.1554\n",
      "TRAIN: EPOCH 0073 / 0100 | BATCH 0006 / 0012 | LOSS 0.1553\n",
      "TRAIN: EPOCH 0073 / 0100 | BATCH 0007 / 0012 | LOSS 0.1550\n",
      "TRAIN: EPOCH 0073 / 0100 | BATCH 0008 / 0012 | LOSS 0.1549\n",
      "TRAIN: EPOCH 0073 / 0100 | BATCH 0009 / 0012 | LOSS 0.1550\n",
      "TRAIN: EPOCH 0073 / 0100 | BATCH 0010 / 0012 | LOSS 0.1545\n",
      "TRAIN: EPOCH 0073 / 0100 | BATCH 0011 / 0012 | LOSS 0.1550\n",
      "TRAIN: EPOCH 0073 / 0100 | BATCH 0012 / 0012 | LOSS 0.1539\n",
      "VALID: EPOCH 0073 / 0100 | BATCH 0001 / 0002 | LOSS 0.1785\n",
      "VALID: EPOCH 0073 / 0100 | BATCH 0002 / 0002 | LOSS 0.2112\n",
      "TRAIN: EPOCH 0074 / 0100 | BATCH 0001 / 0012 | LOSS 0.1623\n",
      "TRAIN: EPOCH 0074 / 0100 | BATCH 0002 / 0012 | LOSS 0.1575\n",
      "TRAIN: EPOCH 0074 / 0100 | BATCH 0003 / 0012 | LOSS 0.1534\n",
      "TRAIN: EPOCH 0074 / 0100 | BATCH 0004 / 0012 | LOSS 0.1501\n",
      "TRAIN: EPOCH 0074 / 0100 | BATCH 0005 / 0012 | LOSS 0.1501\n",
      "TRAIN: EPOCH 0074 / 0100 | BATCH 0006 / 0012 | LOSS 0.1484\n",
      "TRAIN: EPOCH 0074 / 0100 | BATCH 0007 / 0012 | LOSS 0.1511\n",
      "TRAIN: EPOCH 0074 / 0100 | BATCH 0008 / 0012 | LOSS 0.1512\n",
      "TRAIN: EPOCH 0074 / 0100 | BATCH 0009 / 0012 | LOSS 0.1527\n",
      "TRAIN: EPOCH 0074 / 0100 | BATCH 0010 / 0012 | LOSS 0.1532\n",
      "TRAIN: EPOCH 0074 / 0100 | BATCH 0011 / 0012 | LOSS 0.1541\n",
      "TRAIN: EPOCH 0074 / 0100 | BATCH 0012 / 0012 | LOSS 0.1542\n",
      "VALID: EPOCH 0074 / 0100 | BATCH 0001 / 0002 | LOSS 0.1865\n",
      "VALID: EPOCH 0074 / 0100 | BATCH 0002 / 0002 | LOSS 0.2171\n",
      "TRAIN: EPOCH 0075 / 0100 | BATCH 0001 / 0012 | LOSS 0.1680\n",
      "TRAIN: EPOCH 0075 / 0100 | BATCH 0002 / 0012 | LOSS 0.1623\n",
      "TRAIN: EPOCH 0075 / 0100 | BATCH 0003 / 0012 | LOSS 0.1601\n",
      "TRAIN: EPOCH 0075 / 0100 | BATCH 0004 / 0012 | LOSS 0.1601\n",
      "TRAIN: EPOCH 0075 / 0100 | BATCH 0005 / 0012 | LOSS 0.1575\n",
      "TRAIN: EPOCH 0075 / 0100 | BATCH 0006 / 0012 | LOSS 0.1572\n",
      "TRAIN: EPOCH 0075 / 0100 | BATCH 0007 / 0012 | LOSS 0.1577\n",
      "TRAIN: EPOCH 0075 / 0100 | BATCH 0008 / 0012 | LOSS 0.1556\n",
      "TRAIN: EPOCH 0075 / 0100 | BATCH 0009 / 0012 | LOSS 0.1541\n",
      "TRAIN: EPOCH 0075 / 0100 | BATCH 0010 / 0012 | LOSS 0.1544\n",
      "TRAIN: EPOCH 0075 / 0100 | BATCH 0011 / 0012 | LOSS 0.1564\n",
      "TRAIN: EPOCH 0075 / 0100 | BATCH 0012 / 0012 | LOSS 0.1559\n",
      "VALID: EPOCH 0075 / 0100 | BATCH 0001 / 0002 | LOSS 0.1814\n",
      "VALID: EPOCH 0075 / 0100 | BATCH 0002 / 0002 | LOSS 0.2078\n",
      "TRAIN: EPOCH 0076 / 0100 | BATCH 0001 / 0012 | LOSS 0.1639\n",
      "TRAIN: EPOCH 0076 / 0100 | BATCH 0002 / 0012 | LOSS 0.1557\n",
      "TRAIN: EPOCH 0076 / 0100 | BATCH 0003 / 0012 | LOSS 0.1567\n",
      "TRAIN: EPOCH 0076 / 0100 | BATCH 0004 / 0012 | LOSS 0.1563\n",
      "TRAIN: EPOCH 0076 / 0100 | BATCH 0005 / 0012 | LOSS 0.1545\n",
      "TRAIN: EPOCH 0076 / 0100 | BATCH 0006 / 0012 | LOSS 0.1536\n",
      "TRAIN: EPOCH 0076 / 0100 | BATCH 0007 / 0012 | LOSS 0.1520\n",
      "TRAIN: EPOCH 0076 / 0100 | BATCH 0008 / 0012 | LOSS 0.1512\n",
      "TRAIN: EPOCH 0076 / 0100 | BATCH 0009 / 0012 | LOSS 0.1514\n",
      "TRAIN: EPOCH 0076 / 0100 | BATCH 0010 / 0012 | LOSS 0.1542\n",
      "TRAIN: EPOCH 0076 / 0100 | BATCH 0011 / 0012 | LOSS 0.1539\n",
      "TRAIN: EPOCH 0076 / 0100 | BATCH 0012 / 0012 | LOSS 0.1536\n",
      "VALID: EPOCH 0076 / 0100 | BATCH 0001 / 0002 | LOSS 0.2021\n",
      "VALID: EPOCH 0076 / 0100 | BATCH 0002 / 0002 | LOSS 0.2357\n",
      "TRAIN: EPOCH 0077 / 0100 | BATCH 0001 / 0012 | LOSS 0.1489\n",
      "TRAIN: EPOCH 0077 / 0100 | BATCH 0002 / 0012 | LOSS 0.1454\n",
      "TRAIN: EPOCH 0077 / 0100 | BATCH 0003 / 0012 | LOSS 0.1477\n",
      "TRAIN: EPOCH 0077 / 0100 | BATCH 0004 / 0012 | LOSS 0.1505\n",
      "TRAIN: EPOCH 0077 / 0100 | BATCH 0005 / 0012 | LOSS 0.1518\n",
      "TRAIN: EPOCH 0077 / 0100 | BATCH 0006 / 0012 | LOSS 0.1511\n",
      "TRAIN: EPOCH 0077 / 0100 | BATCH 0007 / 0012 | LOSS 0.1515\n",
      "TRAIN: EPOCH 0077 / 0100 | BATCH 0008 / 0012 | LOSS 0.1506\n",
      "TRAIN: EPOCH 0077 / 0100 | BATCH 0009 / 0012 | LOSS 0.1492\n",
      "TRAIN: EPOCH 0077 / 0100 | BATCH 0010 / 0012 | LOSS 0.1508\n",
      "TRAIN: EPOCH 0077 / 0100 | BATCH 0011 / 0012 | LOSS 0.1527\n",
      "TRAIN: EPOCH 0077 / 0100 | BATCH 0012 / 0012 | LOSS 0.1521\n",
      "VALID: EPOCH 0077 / 0100 | BATCH 0001 / 0002 | LOSS 0.1908\n",
      "VALID: EPOCH 0077 / 0100 | BATCH 0002 / 0002 | LOSS 0.2149\n",
      "TRAIN: EPOCH 0078 / 0100 | BATCH 0001 / 0012 | LOSS 0.1361\n",
      "TRAIN: EPOCH 0078 / 0100 | BATCH 0002 / 0012 | LOSS 0.1424\n",
      "TRAIN: EPOCH 0078 / 0100 | BATCH 0003 / 0012 | LOSS 0.1446\n",
      "TRAIN: EPOCH 0078 / 0100 | BATCH 0004 / 0012 | LOSS 0.1479\n",
      "TRAIN: EPOCH 0078 / 0100 | BATCH 0005 / 0012 | LOSS 0.1494\n",
      "TRAIN: EPOCH 0078 / 0100 | BATCH 0006 / 0012 | LOSS 0.1498\n",
      "TRAIN: EPOCH 0078 / 0100 | BATCH 0007 / 0012 | LOSS 0.1476\n",
      "TRAIN: EPOCH 0078 / 0100 | BATCH 0008 / 0012 | LOSS 0.1479\n",
      "TRAIN: EPOCH 0078 / 0100 | BATCH 0009 / 0012 | LOSS 0.1505\n",
      "TRAIN: EPOCH 0078 / 0100 | BATCH 0010 / 0012 | LOSS 0.1498\n",
      "TRAIN: EPOCH 0078 / 0100 | BATCH 0011 / 0012 | LOSS 0.1527\n",
      "TRAIN: EPOCH 0078 / 0100 | BATCH 0012 / 0012 | LOSS 0.1517\n",
      "VALID: EPOCH 0078 / 0100 | BATCH 0001 / 0002 | LOSS 0.1932\n",
      "VALID: EPOCH 0078 / 0100 | BATCH 0002 / 0002 | LOSS 0.2181\n",
      "TRAIN: EPOCH 0079 / 0100 | BATCH 0001 / 0012 | LOSS 0.1523\n",
      "TRAIN: EPOCH 0079 / 0100 | BATCH 0002 / 0012 | LOSS 0.1508\n",
      "TRAIN: EPOCH 0079 / 0100 | BATCH 0003 / 0012 | LOSS 0.1482\n",
      "TRAIN: EPOCH 0079 / 0100 | BATCH 0004 / 0012 | LOSS 0.1465\n",
      "TRAIN: EPOCH 0079 / 0100 | BATCH 0005 / 0012 | LOSS 0.1459\n",
      "TRAIN: EPOCH 0079 / 0100 | BATCH 0006 / 0012 | LOSS 0.1466\n",
      "TRAIN: EPOCH 0079 / 0100 | BATCH 0007 / 0012 | LOSS 0.1466\n",
      "TRAIN: EPOCH 0079 / 0100 | BATCH 0008 / 0012 | LOSS 0.1476\n",
      "TRAIN: EPOCH 0079 / 0100 | BATCH 0009 / 0012 | LOSS 0.1488\n",
      "TRAIN: EPOCH 0079 / 0100 | BATCH 0010 / 0012 | LOSS 0.1467\n",
      "TRAIN: EPOCH 0079 / 0100 | BATCH 0011 / 0012 | LOSS 0.1480\n",
      "TRAIN: EPOCH 0079 / 0100 | BATCH 0012 / 0012 | LOSS 0.1485\n",
      "VALID: EPOCH 0079 / 0100 | BATCH 0001 / 0002 | LOSS 0.1951\n",
      "VALID: EPOCH 0079 / 0100 | BATCH 0002 / 0002 | LOSS 0.2166\n",
      "TRAIN: EPOCH 0080 / 0100 | BATCH 0001 / 0012 | LOSS 0.1393\n",
      "TRAIN: EPOCH 0080 / 0100 | BATCH 0002 / 0012 | LOSS 0.1405\n",
      "TRAIN: EPOCH 0080 / 0100 | BATCH 0003 / 0012 | LOSS 0.1417\n",
      "TRAIN: EPOCH 0080 / 0100 | BATCH 0004 / 0012 | LOSS 0.1463\n",
      "TRAIN: EPOCH 0080 / 0100 | BATCH 0005 / 0012 | LOSS 0.1427\n",
      "TRAIN: EPOCH 0080 / 0100 | BATCH 0006 / 0012 | LOSS 0.1436\n",
      "TRAIN: EPOCH 0080 / 0100 | BATCH 0007 / 0012 | LOSS 0.1438\n",
      "TRAIN: EPOCH 0080 / 0100 | BATCH 0008 / 0012 | LOSS 0.1431\n",
      "TRAIN: EPOCH 0080 / 0100 | BATCH 0009 / 0012 | LOSS 0.1439\n",
      "TRAIN: EPOCH 0080 / 0100 | BATCH 0010 / 0012 | LOSS 0.1442\n",
      "TRAIN: EPOCH 0080 / 0100 | BATCH 0011 / 0012 | LOSS 0.1457\n",
      "TRAIN: EPOCH 0080 / 0100 | BATCH 0012 / 0012 | LOSS 0.1462\n",
      "VALID: EPOCH 0080 / 0100 | BATCH 0001 / 0002 | LOSS 0.1963\n",
      "VALID: EPOCH 0080 / 0100 | BATCH 0002 / 0002 | LOSS 0.2305\n",
      "TRAIN: EPOCH 0081 / 0100 | BATCH 0001 / 0012 | LOSS 0.1585\n",
      "TRAIN: EPOCH 0081 / 0100 | BATCH 0002 / 0012 | LOSS 0.1694\n",
      "TRAIN: EPOCH 0081 / 0100 | BATCH 0003 / 0012 | LOSS 0.1625\n",
      "TRAIN: EPOCH 0081 / 0100 | BATCH 0004 / 0012 | LOSS 0.1572\n",
      "TRAIN: EPOCH 0081 / 0100 | BATCH 0005 / 0012 | LOSS 0.1561\n",
      "TRAIN: EPOCH 0081 / 0100 | BATCH 0006 / 0012 | LOSS 0.1532\n",
      "TRAIN: EPOCH 0081 / 0100 | BATCH 0007 / 0012 | LOSS 0.1558\n",
      "TRAIN: EPOCH 0081 / 0100 | BATCH 0008 / 0012 | LOSS 0.1535\n",
      "TRAIN: EPOCH 0081 / 0100 | BATCH 0009 / 0012 | LOSS 0.1525\n",
      "TRAIN: EPOCH 0081 / 0100 | BATCH 0010 / 0012 | LOSS 0.1518\n",
      "TRAIN: EPOCH 0081 / 0100 | BATCH 0011 / 0012 | LOSS 0.1519\n",
      "TRAIN: EPOCH 0081 / 0100 | BATCH 0012 / 0012 | LOSS 0.1505\n",
      "VALID: EPOCH 0081 / 0100 | BATCH 0001 / 0002 | LOSS 0.1786\n",
      "VALID: EPOCH 0081 / 0100 | BATCH 0002 / 0002 | LOSS 0.2100\n",
      "TRAIN: EPOCH 0082 / 0100 | BATCH 0001 / 0012 | LOSS 0.1547\n",
      "TRAIN: EPOCH 0082 / 0100 | BATCH 0002 / 0012 | LOSS 0.1578\n",
      "TRAIN: EPOCH 0082 / 0100 | BATCH 0003 / 0012 | LOSS 0.1539\n",
      "TRAIN: EPOCH 0082 / 0100 | BATCH 0004 / 0012 | LOSS 0.1647\n",
      "TRAIN: EPOCH 0082 / 0100 | BATCH 0005 / 0012 | LOSS 0.1626\n",
      "TRAIN: EPOCH 0082 / 0100 | BATCH 0006 / 0012 | LOSS 0.1623\n",
      "TRAIN: EPOCH 0082 / 0100 | BATCH 0007 / 0012 | LOSS 0.1589\n",
      "TRAIN: EPOCH 0082 / 0100 | BATCH 0008 / 0012 | LOSS 0.1572\n",
      "TRAIN: EPOCH 0082 / 0100 | BATCH 0009 / 0012 | LOSS 0.1548\n",
      "TRAIN: EPOCH 0082 / 0100 | BATCH 0010 / 0012 | LOSS 0.1532\n",
      "TRAIN: EPOCH 0082 / 0100 | BATCH 0011 / 0012 | LOSS 0.1536\n",
      "TRAIN: EPOCH 0082 / 0100 | BATCH 0012 / 0012 | LOSS 0.1539\n",
      "VALID: EPOCH 0082 / 0100 | BATCH 0001 / 0002 | LOSS 0.1869\n",
      "VALID: EPOCH 0082 / 0100 | BATCH 0002 / 0002 | LOSS 0.2126\n",
      "TRAIN: EPOCH 0083 / 0100 | BATCH 0001 / 0012 | LOSS 0.1434\n",
      "TRAIN: EPOCH 0083 / 0100 | BATCH 0002 / 0012 | LOSS 0.1553\n",
      "TRAIN: EPOCH 0083 / 0100 | BATCH 0003 / 0012 | LOSS 0.1532\n",
      "TRAIN: EPOCH 0083 / 0100 | BATCH 0004 / 0012 | LOSS 0.1515\n",
      "TRAIN: EPOCH 0083 / 0100 | BATCH 0005 / 0012 | LOSS 0.1508\n",
      "TRAIN: EPOCH 0083 / 0100 | BATCH 0006 / 0012 | LOSS 0.1505\n",
      "TRAIN: EPOCH 0083 / 0100 | BATCH 0007 / 0012 | LOSS 0.1510\n",
      "TRAIN: EPOCH 0083 / 0100 | BATCH 0008 / 0012 | LOSS 0.1513\n",
      "TRAIN: EPOCH 0083 / 0100 | BATCH 0009 / 0012 | LOSS 0.1499\n",
      "TRAIN: EPOCH 0083 / 0100 | BATCH 0010 / 0012 | LOSS 0.1502\n",
      "TRAIN: EPOCH 0083 / 0100 | BATCH 0011 / 0012 | LOSS 0.1507\n",
      "TRAIN: EPOCH 0083 / 0100 | BATCH 0012 / 0012 | LOSS 0.1495\n",
      "VALID: EPOCH 0083 / 0100 | BATCH 0001 / 0002 | LOSS 0.1968\n",
      "VALID: EPOCH 0083 / 0100 | BATCH 0002 / 0002 | LOSS 0.2301\n",
      "TRAIN: EPOCH 0084 / 0100 | BATCH 0001 / 0012 | LOSS 0.1435\n",
      "TRAIN: EPOCH 0084 / 0100 | BATCH 0002 / 0012 | LOSS 0.1447\n",
      "TRAIN: EPOCH 0084 / 0100 | BATCH 0003 / 0012 | LOSS 0.1483\n",
      "TRAIN: EPOCH 0084 / 0100 | BATCH 0004 / 0012 | LOSS 0.1449\n",
      "TRAIN: EPOCH 0084 / 0100 | BATCH 0005 / 0012 | LOSS 0.1460\n",
      "TRAIN: EPOCH 0084 / 0100 | BATCH 0006 / 0012 | LOSS 0.1427\n",
      "TRAIN: EPOCH 0084 / 0100 | BATCH 0007 / 0012 | LOSS 0.1448\n",
      "TRAIN: EPOCH 0084 / 0100 | BATCH 0008 / 0012 | LOSS 0.1454\n",
      "TRAIN: EPOCH 0084 / 0100 | BATCH 0009 / 0012 | LOSS 0.1470\n",
      "TRAIN: EPOCH 0084 / 0100 | BATCH 0010 / 0012 | LOSS 0.1481\n",
      "TRAIN: EPOCH 0084 / 0100 | BATCH 0011 / 0012 | LOSS 0.1495\n",
      "TRAIN: EPOCH 0084 / 0100 | BATCH 0012 / 0012 | LOSS 0.1488\n",
      "VALID: EPOCH 0084 / 0100 | BATCH 0001 / 0002 | LOSS 0.1883\n",
      "VALID: EPOCH 0084 / 0100 | BATCH 0002 / 0002 | LOSS 0.2316\n",
      "TRAIN: EPOCH 0085 / 0100 | BATCH 0001 / 0012 | LOSS 0.1340\n",
      "TRAIN: EPOCH 0085 / 0100 | BATCH 0002 / 0012 | LOSS 0.1539\n",
      "TRAIN: EPOCH 0085 / 0100 | BATCH 0003 / 0012 | LOSS 0.1512\n",
      "TRAIN: EPOCH 0085 / 0100 | BATCH 0004 / 0012 | LOSS 0.1543\n",
      "TRAIN: EPOCH 0085 / 0100 | BATCH 0005 / 0012 | LOSS 0.1555\n",
      "TRAIN: EPOCH 0085 / 0100 | BATCH 0006 / 0012 | LOSS 0.1585\n",
      "TRAIN: EPOCH 0085 / 0100 | BATCH 0007 / 0012 | LOSS 0.1581\n",
      "TRAIN: EPOCH 0085 / 0100 | BATCH 0008 / 0012 | LOSS 0.1576\n",
      "TRAIN: EPOCH 0085 / 0100 | BATCH 0009 / 0012 | LOSS 0.1558\n",
      "TRAIN: EPOCH 0085 / 0100 | BATCH 0010 / 0012 | LOSS 0.1555\n",
      "TRAIN: EPOCH 0085 / 0100 | BATCH 0011 / 0012 | LOSS 0.1542\n",
      "TRAIN: EPOCH 0085 / 0100 | BATCH 0012 / 0012 | LOSS 0.1532\n",
      "VALID: EPOCH 0085 / 0100 | BATCH 0001 / 0002 | LOSS 0.1833\n",
      "VALID: EPOCH 0085 / 0100 | BATCH 0002 / 0002 | LOSS 0.2141\n",
      "TRAIN: EPOCH 0086 / 0100 | BATCH 0001 / 0012 | LOSS 0.1394\n",
      "TRAIN: EPOCH 0086 / 0100 | BATCH 0002 / 0012 | LOSS 0.1456\n",
      "TRAIN: EPOCH 0086 / 0100 | BATCH 0003 / 0012 | LOSS 0.1501\n",
      "TRAIN: EPOCH 0086 / 0100 | BATCH 0004 / 0012 | LOSS 0.1463\n",
      "TRAIN: EPOCH 0086 / 0100 | BATCH 0005 / 0012 | LOSS 0.1450\n",
      "TRAIN: EPOCH 0086 / 0100 | BATCH 0006 / 0012 | LOSS 0.1473\n",
      "TRAIN: EPOCH 0086 / 0100 | BATCH 0007 / 0012 | LOSS 0.1477\n",
      "TRAIN: EPOCH 0086 / 0100 | BATCH 0008 / 0012 | LOSS 0.1462\n",
      "TRAIN: EPOCH 0086 / 0100 | BATCH 0009 / 0012 | LOSS 0.1469\n",
      "TRAIN: EPOCH 0086 / 0100 | BATCH 0010 / 0012 | LOSS 0.1476\n",
      "TRAIN: EPOCH 0086 / 0100 | BATCH 0011 / 0012 | LOSS 0.1470\n",
      "TRAIN: EPOCH 0086 / 0100 | BATCH 0012 / 0012 | LOSS 0.1500\n",
      "VALID: EPOCH 0086 / 0100 | BATCH 0001 / 0002 | LOSS 0.1902\n",
      "VALID: EPOCH 0086 / 0100 | BATCH 0002 / 0002 | LOSS 0.2384\n",
      "TRAIN: EPOCH 0087 / 0100 | BATCH 0001 / 0012 | LOSS 0.1673\n",
      "TRAIN: EPOCH 0087 / 0100 | BATCH 0002 / 0012 | LOSS 0.1630\n",
      "TRAIN: EPOCH 0087 / 0100 | BATCH 0003 / 0012 | LOSS 0.1604\n",
      "TRAIN: EPOCH 0087 / 0100 | BATCH 0004 / 0012 | LOSS 0.1583\n",
      "TRAIN: EPOCH 0087 / 0100 | BATCH 0005 / 0012 | LOSS 0.1537\n",
      "TRAIN: EPOCH 0087 / 0100 | BATCH 0006 / 0012 | LOSS 0.1521\n",
      "TRAIN: EPOCH 0087 / 0100 | BATCH 0007 / 0012 | LOSS 0.1524\n",
      "TRAIN: EPOCH 0087 / 0100 | BATCH 0008 / 0012 | LOSS 0.1519\n",
      "TRAIN: EPOCH 0087 / 0100 | BATCH 0009 / 0012 | LOSS 0.1505\n",
      "TRAIN: EPOCH 0087 / 0100 | BATCH 0010 / 0012 | LOSS 0.1491\n",
      "TRAIN: EPOCH 0087 / 0100 | BATCH 0011 / 0012 | LOSS 0.1490\n",
      "TRAIN: EPOCH 0087 / 0100 | BATCH 0012 / 0012 | LOSS 0.1473\n",
      "VALID: EPOCH 0087 / 0100 | BATCH 0001 / 0002 | LOSS 0.1998\n",
      "VALID: EPOCH 0087 / 0100 | BATCH 0002 / 0002 | LOSS 0.2243\n",
      "TRAIN: EPOCH 0088 / 0100 | BATCH 0001 / 0012 | LOSS 0.1482\n",
      "TRAIN: EPOCH 0088 / 0100 | BATCH 0002 / 0012 | LOSS 0.1439\n",
      "TRAIN: EPOCH 0088 / 0100 | BATCH 0003 / 0012 | LOSS 0.1464\n",
      "TRAIN: EPOCH 0088 / 0100 | BATCH 0004 / 0012 | LOSS 0.1444\n",
      "TRAIN: EPOCH 0088 / 0100 | BATCH 0005 / 0012 | LOSS 0.1470\n",
      "TRAIN: EPOCH 0088 / 0100 | BATCH 0006 / 0012 | LOSS 0.1464\n",
      "TRAIN: EPOCH 0088 / 0100 | BATCH 0007 / 0012 | LOSS 0.1443\n",
      "TRAIN: EPOCH 0088 / 0100 | BATCH 0008 / 0012 | LOSS 0.1451\n",
      "TRAIN: EPOCH 0088 / 0100 | BATCH 0009 / 0012 | LOSS 0.1470\n",
      "TRAIN: EPOCH 0088 / 0100 | BATCH 0010 / 0012 | LOSS 0.1486\n",
      "TRAIN: EPOCH 0088 / 0100 | BATCH 0011 / 0012 | LOSS 0.1487\n",
      "TRAIN: EPOCH 0088 / 0100 | BATCH 0012 / 0012 | LOSS 0.1498\n",
      "VALID: EPOCH 0088 / 0100 | BATCH 0001 / 0002 | LOSS 0.1882\n",
      "VALID: EPOCH 0088 / 0100 | BATCH 0002 / 0002 | LOSS 0.2250\n",
      "TRAIN: EPOCH 0089 / 0100 | BATCH 0001 / 0012 | LOSS 0.1509\n",
      "TRAIN: EPOCH 0089 / 0100 | BATCH 0002 / 0012 | LOSS 0.1538\n",
      "TRAIN: EPOCH 0089 / 0100 | BATCH 0003 / 0012 | LOSS 0.1531\n",
      "TRAIN: EPOCH 0089 / 0100 | BATCH 0004 / 0012 | LOSS 0.1545\n",
      "TRAIN: EPOCH 0089 / 0100 | BATCH 0005 / 0012 | LOSS 0.1515\n",
      "TRAIN: EPOCH 0089 / 0100 | BATCH 0006 / 0012 | LOSS 0.1527\n",
      "TRAIN: EPOCH 0089 / 0100 | BATCH 0007 / 0012 | LOSS 0.1499\n",
      "TRAIN: EPOCH 0089 / 0100 | BATCH 0008 / 0012 | LOSS 0.1474\n",
      "TRAIN: EPOCH 0089 / 0100 | BATCH 0009 / 0012 | LOSS 0.1474\n",
      "TRAIN: EPOCH 0089 / 0100 | BATCH 0010 / 0012 | LOSS 0.1464\n",
      "TRAIN: EPOCH 0089 / 0100 | BATCH 0011 / 0012 | LOSS 0.1452\n",
      "TRAIN: EPOCH 0089 / 0100 | BATCH 0012 / 0012 | LOSS 0.1471\n",
      "VALID: EPOCH 0089 / 0100 | BATCH 0001 / 0002 | LOSS 0.1850\n",
      "VALID: EPOCH 0089 / 0100 | BATCH 0002 / 0002 | LOSS 0.2131\n",
      "TRAIN: EPOCH 0090 / 0100 | BATCH 0001 / 0012 | LOSS 0.1422\n",
      "TRAIN: EPOCH 0090 / 0100 | BATCH 0002 / 0012 | LOSS 0.1353\n",
      "TRAIN: EPOCH 0090 / 0100 | BATCH 0003 / 0012 | LOSS 0.1451\n",
      "TRAIN: EPOCH 0090 / 0100 | BATCH 0004 / 0012 | LOSS 0.1464\n",
      "TRAIN: EPOCH 0090 / 0100 | BATCH 0005 / 0012 | LOSS 0.1466\n",
      "TRAIN: EPOCH 0090 / 0100 | BATCH 0006 / 0012 | LOSS 0.1480\n",
      "TRAIN: EPOCH 0090 / 0100 | BATCH 0007 / 0012 | LOSS 0.1483\n",
      "TRAIN: EPOCH 0090 / 0100 | BATCH 0008 / 0012 | LOSS 0.1463\n",
      "TRAIN: EPOCH 0090 / 0100 | BATCH 0009 / 0012 | LOSS 0.1462\n",
      "TRAIN: EPOCH 0090 / 0100 | BATCH 0010 / 0012 | LOSS 0.1449\n",
      "TRAIN: EPOCH 0090 / 0100 | BATCH 0011 / 0012 | LOSS 0.1456\n",
      "TRAIN: EPOCH 0090 / 0100 | BATCH 0012 / 0012 | LOSS 0.1480\n",
      "VALID: EPOCH 0090 / 0100 | BATCH 0001 / 0002 | LOSS 0.1842\n",
      "VALID: EPOCH 0090 / 0100 | BATCH 0002 / 0002 | LOSS 0.2255\n",
      "TRAIN: EPOCH 0091 / 0100 | BATCH 0001 / 0012 | LOSS 0.1470\n",
      "TRAIN: EPOCH 0091 / 0100 | BATCH 0002 / 0012 | LOSS 0.1453\n",
      "TRAIN: EPOCH 0091 / 0100 | BATCH 0003 / 0012 | LOSS 0.1555\n",
      "TRAIN: EPOCH 0091 / 0100 | BATCH 0004 / 0012 | LOSS 0.1551\n",
      "TRAIN: EPOCH 0091 / 0100 | BATCH 0005 / 0012 | LOSS 0.1535\n",
      "TRAIN: EPOCH 0091 / 0100 | BATCH 0006 / 0012 | LOSS 0.1537\n",
      "TRAIN: EPOCH 0091 / 0100 | BATCH 0007 / 0012 | LOSS 0.1531\n",
      "TRAIN: EPOCH 0091 / 0100 | BATCH 0008 / 0012 | LOSS 0.1517\n",
      "TRAIN: EPOCH 0091 / 0100 | BATCH 0009 / 0012 | LOSS 0.1508\n",
      "TRAIN: EPOCH 0091 / 0100 | BATCH 0010 / 0012 | LOSS 0.1507\n",
      "TRAIN: EPOCH 0091 / 0100 | BATCH 0011 / 0012 | LOSS 0.1496\n",
      "TRAIN: EPOCH 0091 / 0100 | BATCH 0012 / 0012 | LOSS 0.1490\n",
      "VALID: EPOCH 0091 / 0100 | BATCH 0001 / 0002 | LOSS 0.2324\n",
      "VALID: EPOCH 0091 / 0100 | BATCH 0002 / 0002 | LOSS 0.2548\n",
      "TRAIN: EPOCH 0092 / 0100 | BATCH 0001 / 0012 | LOSS 0.1311\n",
      "TRAIN: EPOCH 0092 / 0100 | BATCH 0002 / 0012 | LOSS 0.1400\n",
      "TRAIN: EPOCH 0092 / 0100 | BATCH 0003 / 0012 | LOSS 0.1553\n",
      "TRAIN: EPOCH 0092 / 0100 | BATCH 0004 / 0012 | LOSS 0.1519\n",
      "TRAIN: EPOCH 0092 / 0100 | BATCH 0005 / 0012 | LOSS 0.1480\n",
      "TRAIN: EPOCH 0092 / 0100 | BATCH 0006 / 0012 | LOSS 0.1498\n",
      "TRAIN: EPOCH 0092 / 0100 | BATCH 0007 / 0012 | LOSS 0.1489\n",
      "TRAIN: EPOCH 0092 / 0100 | BATCH 0008 / 0012 | LOSS 0.1484\n",
      "TRAIN: EPOCH 0092 / 0100 | BATCH 0009 / 0012 | LOSS 0.1479\n",
      "TRAIN: EPOCH 0092 / 0100 | BATCH 0010 / 0012 | LOSS 0.1482\n",
      "TRAIN: EPOCH 0092 / 0100 | BATCH 0011 / 0012 | LOSS 0.1487\n",
      "TRAIN: EPOCH 0092 / 0100 | BATCH 0012 / 0012 | LOSS 0.1488\n",
      "VALID: EPOCH 0092 / 0100 | BATCH 0001 / 0002 | LOSS 0.1805\n",
      "VALID: EPOCH 0092 / 0100 | BATCH 0002 / 0002 | LOSS 0.2103\n",
      "TRAIN: EPOCH 0093 / 0100 | BATCH 0001 / 0012 | LOSS 0.1686\n",
      "TRAIN: EPOCH 0093 / 0100 | BATCH 0002 / 0012 | LOSS 0.1555\n",
      "TRAIN: EPOCH 0093 / 0100 | BATCH 0003 / 0012 | LOSS 0.1465\n",
      "TRAIN: EPOCH 0093 / 0100 | BATCH 0004 / 0012 | LOSS 0.1469\n",
      "TRAIN: EPOCH 0093 / 0100 | BATCH 0005 / 0012 | LOSS 0.1458\n",
      "TRAIN: EPOCH 0093 / 0100 | BATCH 0006 / 0012 | LOSS 0.1438\n",
      "TRAIN: EPOCH 0093 / 0100 | BATCH 0007 / 0012 | LOSS 0.1450\n",
      "TRAIN: EPOCH 0093 / 0100 | BATCH 0008 / 0012 | LOSS 0.1433\n",
      "TRAIN: EPOCH 0093 / 0100 | BATCH 0009 / 0012 | LOSS 0.1435\n",
      "TRAIN: EPOCH 0093 / 0100 | BATCH 0010 / 0012 | LOSS 0.1451\n",
      "TRAIN: EPOCH 0093 / 0100 | BATCH 0011 / 0012 | LOSS 0.1470\n",
      "TRAIN: EPOCH 0093 / 0100 | BATCH 0012 / 0012 | LOSS 0.1460\n",
      "VALID: EPOCH 0093 / 0100 | BATCH 0001 / 0002 | LOSS 0.1879\n",
      "VALID: EPOCH 0093 / 0100 | BATCH 0002 / 0002 | LOSS 0.2306\n",
      "TRAIN: EPOCH 0094 / 0100 | BATCH 0001 / 0012 | LOSS 0.1409\n",
      "TRAIN: EPOCH 0094 / 0100 | BATCH 0002 / 0012 | LOSS 0.1442\n",
      "TRAIN: EPOCH 0094 / 0100 | BATCH 0003 / 0012 | LOSS 0.1451\n",
      "TRAIN: EPOCH 0094 / 0100 | BATCH 0004 / 0012 | LOSS 0.1432\n",
      "TRAIN: EPOCH 0094 / 0100 | BATCH 0005 / 0012 | LOSS 0.1470\n",
      "TRAIN: EPOCH 0094 / 0100 | BATCH 0006 / 0012 | LOSS 0.1483\n",
      "TRAIN: EPOCH 0094 / 0100 | BATCH 0007 / 0012 | LOSS 0.1499\n",
      "TRAIN: EPOCH 0094 / 0100 | BATCH 0008 / 0012 | LOSS 0.1502\n",
      "TRAIN: EPOCH 0094 / 0100 | BATCH 0009 / 0012 | LOSS 0.1504\n",
      "TRAIN: EPOCH 0094 / 0100 | BATCH 0010 / 0012 | LOSS 0.1485\n",
      "TRAIN: EPOCH 0094 / 0100 | BATCH 0011 / 0012 | LOSS 0.1466\n",
      "TRAIN: EPOCH 0094 / 0100 | BATCH 0012 / 0012 | LOSS 0.1456\n",
      "VALID: EPOCH 0094 / 0100 | BATCH 0001 / 0002 | LOSS 0.2102\n",
      "VALID: EPOCH 0094 / 0100 | BATCH 0002 / 0002 | LOSS 0.2373\n",
      "TRAIN: EPOCH 0095 / 0100 | BATCH 0001 / 0012 | LOSS 0.1398\n",
      "TRAIN: EPOCH 0095 / 0100 | BATCH 0002 / 0012 | LOSS 0.1421\n",
      "TRAIN: EPOCH 0095 / 0100 | BATCH 0003 / 0012 | LOSS 0.1464\n",
      "TRAIN: EPOCH 0095 / 0100 | BATCH 0004 / 0012 | LOSS 0.1454\n",
      "TRAIN: EPOCH 0095 / 0100 | BATCH 0005 / 0012 | LOSS 0.1449\n",
      "TRAIN: EPOCH 0095 / 0100 | BATCH 0006 / 0012 | LOSS 0.1432\n",
      "TRAIN: EPOCH 0095 / 0100 | BATCH 0007 / 0012 | LOSS 0.1428\n",
      "TRAIN: EPOCH 0095 / 0100 | BATCH 0008 / 0012 | LOSS 0.1422\n",
      "TRAIN: EPOCH 0095 / 0100 | BATCH 0009 / 0012 | LOSS 0.1431\n",
      "TRAIN: EPOCH 0095 / 0100 | BATCH 0010 / 0012 | LOSS 0.1444\n",
      "TRAIN: EPOCH 0095 / 0100 | BATCH 0011 / 0012 | LOSS 0.1428\n",
      "TRAIN: EPOCH 0095 / 0100 | BATCH 0012 / 0012 | LOSS 0.1433\n",
      "VALID: EPOCH 0095 / 0100 | BATCH 0001 / 0002 | LOSS 0.1951\n",
      "VALID: EPOCH 0095 / 0100 | BATCH 0002 / 0002 | LOSS 0.2265\n",
      "TRAIN: EPOCH 0096 / 0100 | BATCH 0001 / 0012 | LOSS 0.1483\n",
      "TRAIN: EPOCH 0096 / 0100 | BATCH 0002 / 0012 | LOSS 0.1442\n",
      "TRAIN: EPOCH 0096 / 0100 | BATCH 0003 / 0012 | LOSS 0.1438\n",
      "TRAIN: EPOCH 0096 / 0100 | BATCH 0004 / 0012 | LOSS 0.1457\n",
      "TRAIN: EPOCH 0096 / 0100 | BATCH 0005 / 0012 | LOSS 0.1450\n",
      "TRAIN: EPOCH 0096 / 0100 | BATCH 0006 / 0012 | LOSS 0.1442\n",
      "TRAIN: EPOCH 0096 / 0100 | BATCH 0007 / 0012 | LOSS 0.1420\n",
      "TRAIN: EPOCH 0096 / 0100 | BATCH 0008 / 0012 | LOSS 0.1422\n",
      "TRAIN: EPOCH 0096 / 0100 | BATCH 0009 / 0012 | LOSS 0.1424\n",
      "TRAIN: EPOCH 0096 / 0100 | BATCH 0010 / 0012 | LOSS 0.1433\n",
      "TRAIN: EPOCH 0096 / 0100 | BATCH 0011 / 0012 | LOSS 0.1429\n",
      "TRAIN: EPOCH 0096 / 0100 | BATCH 0012 / 0012 | LOSS 0.1421\n",
      "VALID: EPOCH 0096 / 0100 | BATCH 0001 / 0002 | LOSS 0.1827\n",
      "VALID: EPOCH 0096 / 0100 | BATCH 0002 / 0002 | LOSS 0.2144\n",
      "TRAIN: EPOCH 0097 / 0100 | BATCH 0001 / 0012 | LOSS 0.1374\n",
      "TRAIN: EPOCH 0097 / 0100 | BATCH 0002 / 0012 | LOSS 0.1441\n",
      "TRAIN: EPOCH 0097 / 0100 | BATCH 0003 / 0012 | LOSS 0.1459\n",
      "TRAIN: EPOCH 0097 / 0100 | BATCH 0004 / 0012 | LOSS 0.1465\n",
      "TRAIN: EPOCH 0097 / 0100 | BATCH 0005 / 0012 | LOSS 0.1471\n",
      "TRAIN: EPOCH 0097 / 0100 | BATCH 0006 / 0012 | LOSS 0.1470\n",
      "TRAIN: EPOCH 0097 / 0100 | BATCH 0007 / 0012 | LOSS 0.1448\n",
      "TRAIN: EPOCH 0097 / 0100 | BATCH 0008 / 0012 | LOSS 0.1428\n",
      "TRAIN: EPOCH 0097 / 0100 | BATCH 0009 / 0012 | LOSS 0.1428\n",
      "TRAIN: EPOCH 0097 / 0100 | BATCH 0010 / 0012 | LOSS 0.1431\n",
      "TRAIN: EPOCH 0097 / 0100 | BATCH 0011 / 0012 | LOSS 0.1439\n",
      "TRAIN: EPOCH 0097 / 0100 | BATCH 0012 / 0012 | LOSS 0.1439\n",
      "VALID: EPOCH 0097 / 0100 | BATCH 0001 / 0002 | LOSS 0.1838\n",
      "VALID: EPOCH 0097 / 0100 | BATCH 0002 / 0002 | LOSS 0.2287\n",
      "TRAIN: EPOCH 0098 / 0100 | BATCH 0001 / 0012 | LOSS 0.1593\n",
      "TRAIN: EPOCH 0098 / 0100 | BATCH 0002 / 0012 | LOSS 0.1421\n",
      "TRAIN: EPOCH 0098 / 0100 | BATCH 0003 / 0012 | LOSS 0.1380\n",
      "TRAIN: EPOCH 0098 / 0100 | BATCH 0004 / 0012 | LOSS 0.1401\n",
      "TRAIN: EPOCH 0098 / 0100 | BATCH 0005 / 0012 | LOSS 0.1407\n",
      "TRAIN: EPOCH 0098 / 0100 | BATCH 0006 / 0012 | LOSS 0.1400\n",
      "TRAIN: EPOCH 0098 / 0100 | BATCH 0007 / 0012 | LOSS 0.1393\n",
      "TRAIN: EPOCH 0098 / 0100 | BATCH 0008 / 0012 | LOSS 0.1388\n",
      "TRAIN: EPOCH 0098 / 0100 | BATCH 0009 / 0012 | LOSS 0.1390\n",
      "TRAIN: EPOCH 0098 / 0100 | BATCH 0010 / 0012 | LOSS 0.1404\n",
      "TRAIN: EPOCH 0098 / 0100 | BATCH 0011 / 0012 | LOSS 0.1433\n",
      "TRAIN: EPOCH 0098 / 0100 | BATCH 0012 / 0012 | LOSS 0.1426\n",
      "VALID: EPOCH 0098 / 0100 | BATCH 0001 / 0002 | LOSS 0.2007\n",
      "VALID: EPOCH 0098 / 0100 | BATCH 0002 / 0002 | LOSS 0.2395\n",
      "TRAIN: EPOCH 0099 / 0100 | BATCH 0001 / 0012 | LOSS 0.1412\n",
      "TRAIN: EPOCH 0099 / 0100 | BATCH 0002 / 0012 | LOSS 0.1370\n",
      "TRAIN: EPOCH 0099 / 0100 | BATCH 0003 / 0012 | LOSS 0.1396\n",
      "TRAIN: EPOCH 0099 / 0100 | BATCH 0004 / 0012 | LOSS 0.1379\n",
      "TRAIN: EPOCH 0099 / 0100 | BATCH 0005 / 0012 | LOSS 0.1445\n",
      "TRAIN: EPOCH 0099 / 0100 | BATCH 0006 / 0012 | LOSS 0.1456\n",
      "TRAIN: EPOCH 0099 / 0100 | BATCH 0007 / 0012 | LOSS 0.1475\n",
      "TRAIN: EPOCH 0099 / 0100 | BATCH 0008 / 0012 | LOSS 0.1452\n",
      "TRAIN: EPOCH 0099 / 0100 | BATCH 0009 / 0012 | LOSS 0.1454\n",
      "TRAIN: EPOCH 0099 / 0100 | BATCH 0010 / 0012 | LOSS 0.1448\n",
      "TRAIN: EPOCH 0099 / 0100 | BATCH 0011 / 0012 | LOSS 0.1445\n",
      "TRAIN: EPOCH 0099 / 0100 | BATCH 0012 / 0012 | LOSS 0.1440\n",
      "VALID: EPOCH 0099 / 0100 | BATCH 0001 / 0002 | LOSS 0.1970\n",
      "VALID: EPOCH 0099 / 0100 | BATCH 0002 / 0002 | LOSS 0.2452\n",
      "TRAIN: EPOCH 0100 / 0100 | BATCH 0001 / 0012 | LOSS 0.1316\n",
      "TRAIN: EPOCH 0100 / 0100 | BATCH 0002 / 0012 | LOSS 0.1327\n",
      "TRAIN: EPOCH 0100 / 0100 | BATCH 0003 / 0012 | LOSS 0.1354\n",
      "TRAIN: EPOCH 0100 / 0100 | BATCH 0004 / 0012 | LOSS 0.1373\n",
      "TRAIN: EPOCH 0100 / 0100 | BATCH 0005 / 0012 | LOSS 0.1434\n",
      "TRAIN: EPOCH 0100 / 0100 | BATCH 0006 / 0012 | LOSS 0.1452\n",
      "TRAIN: EPOCH 0100 / 0100 | BATCH 0007 / 0012 | LOSS 0.1477\n",
      "TRAIN: EPOCH 0100 / 0100 | BATCH 0008 / 0012 | LOSS 0.1462\n",
      "TRAIN: EPOCH 0100 / 0100 | BATCH 0009 / 0012 | LOSS 0.1456\n",
      "TRAIN: EPOCH 0100 / 0100 | BATCH 0010 / 0012 | LOSS 0.1468\n",
      "TRAIN: EPOCH 0100 / 0100 | BATCH 0011 / 0012 | LOSS 0.1461\n",
      "TRAIN: EPOCH 0100 / 0100 | BATCH 0012 / 0012 | LOSS 0.1447\n",
      "VALID: EPOCH 0100 / 0100 | BATCH 0001 / 0002 | LOSS 0.1965\n",
      "VALID: EPOCH 0100 / 0100 | BATCH 0002 / 0002 | LOSS 0.2451\n"
     ]
    }
   ],
   "source": [
    "!python '/home/work/jimin/U-Net/train.py'   # 배치사이즈 2로 줄임   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-25 06:10:03.454286: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-25 06:10:03.492431: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-25 06:10:03.492468: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-25 06:10:03.493582: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-25 06:10:03.499533: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-25 06:10:04.375140: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "TEST: BATCH 0001 / 0001 | LOSS 0.2270\n",
      "AVERAGE TEST: BATCH 0001 / 0001 | LOSS 0.2270\n"
     ]
    }
   ],
   "source": [
    "!python '/home/work/jimin/U-Net/eval.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-25 06:21:43.806165: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-25 06:21:43.843701: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-25 06:21:43.843742: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-25 06:21:43.844791: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-25 06:21:43.850564: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-25 06:21:44.730875: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "learning rate: 1.0000e-02\n",
      "batch size: 2\n",
      "number of epoch: 300\n",
      "data dir: /home/work/jimin/U-Net/datasets\n",
      "ckpt dir: /home/work/jimin/U-Net/checkpoint_v2\n",
      "log dir: /home/work/jimin/U-Net/log_v2\n",
      "result dir: /home/work/jimin/U-Net/result_v2\n",
      "mode: test\n",
      "TEST: BATCH 0001 / 0002 | LOSS 0.6671\n",
      "TEST: BATCH 0002 / 0002 | LOSS 0.6676\n",
      "AVERAGE TEST: BATCH 0002 / 0002 | LOSS 0.6676\n"
     ]
    }
   ],
   "source": [
    "!python '/home/work/jimin/U-Net/train.py' \\\n",
    "--lr 1e-2 --batch_size 2 --num_epoch 300 \\\n",
    "--data_dir \"/home/work/jimin/U-Net/datasets\" \\\n",
    "--ckpt_dir \"/home/work/jimin/U-Net/checkpoint_v2\" \\\n",
    "--log_dir \"/home/work/jimin/U-Net/log_v2\" \\\n",
    "--result_dir \"/home/work/jimin/U-Net/result_v2\" \\\n",
    "--mode \"test\" \\\n",
    "--train_continue \"off\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure(640x480)\n"
     ]
    }
   ],
   "source": [
    "!python '/home/work/jimin/U-Net/display_results.py'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
